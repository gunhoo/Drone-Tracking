{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have been save the data, you don't have to preprocessing and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_path = '../../data/drone/*.wav'\n",
    "background_path = '../../data/background/*.wav'\n",
    "\n",
    "drone_files = glob.glob(drone_path)\n",
    "background_files = glob.glob(background_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 44100\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983765,)\n",
      "(2799903,)\n"
     ]
    }
   ],
   "source": [
    "drone_raw = load(drone_files)\n",
    "background_raw = load(background_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=44100, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983765,)\n",
      "small end: (16, 12)\n",
      "small end: (16, 4)\n",
      "(2799903,)\n",
      "small end: (16, 13)\n",
      "small end: (16, 5)\n",
      "(727, 16, 16) (727,)\n",
      "(682, 16, 16) (682,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_drone, y_drone = mfcc4(drone_raw, 1)\n",
    "mfcc_background, y_background = mfcc4(background_raw, 0)\n",
    "\n",
    "print(mfcc_drone.shape, y_drone.shape)\n",
    "print(mfcc_background.shape, y_background.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 16, 16) (1409,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_drone, mfcc_background), axis=0)\n",
    "#X = np.concatenate((mfcc_drone), axis=0)\n",
    "#X = X.reshape(-1, 16,16,1)\n",
    "y = np.hstack((y_drone, y_background))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 2)\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(901, 16, 16) (282, 16, 16)\n",
      "(226, 16, 16) (226, 2)\n",
      "(901, 2) (282, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save('../../data/X_train', X_train)\n",
    "np.save('../../data/X_test', X_test)\n",
    "np.save('../../model/X_val', X_val)\n",
    "np.save('../../model/y_val', y_val)\n",
    "np.save('../../data/y_train', y_train)\n",
    "np.save('../../data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load('../../data/X_train.npy')\n",
    "X_test = np.load('../../data/X_test.npy')\n",
    "X_val = np.load('../../model/X_val.npy')\n",
    "y_val = np.load('../../model/y_val.npy')\n",
    "y_train = np.load('../../data/y_train.npy')\n",
    "y_test = np.load('../../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - One convolutional layer /w no dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Experiment 3-2\n",
    "- learning rate 0.005\n",
    "- pooling stride 1x1\n",
    "- #filter 1\n",
    "- best result among every other settings\n",
    "- cost kept fluctuated during training. (0.8 -> 1.3) -- why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.0002  # 0.005\n",
    "training_epochs = 500 # 수정해봐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# dropout넣어야하나\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# 여기도\n",
    "flat = tf.reshape(pool2, [-1, 16*16*1])\n",
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_val2 = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model_path = '../../model/CNN/cnn_model'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0001 cost =  10.838669459 val =  0.451327\n",
      "226 Epoch: 0002 cost =  3.389595389 val =  0.561947\n",
      "226 Epoch: 0003 cost =  1.424339657 val =  0.831858\n",
      "226 Epoch: 0004 cost =  1.265684048 val =  0.924779\n",
      "226 Epoch: 0005 cost =  0.187130071 val =  0.893805\n",
      "226 Epoch: 0006 cost =  0.388400321 val =  0.969027\n",
      "226 Epoch: 0007 cost =  0.069858460 val =  0.982301\n",
      "226 Epoch: 0008 cost =  0.183176157 val =  0.982301\n",
      "226 Epoch: 0009 cost =  0.105825182 val =  0.991150\n",
      "226 Epoch: 0010 cost =  0.042197992 val =  0.977876\n",
      "226 Epoch: 0011 cost =  0.071393199 val =  0.977876\n",
      "226 Epoch: 0012 cost =  0.039207292 val =  0.991150\n",
      "226 Epoch: 0013 cost =  0.034639178 val =  0.991150\n",
      "226 Epoch: 0014 cost =  0.040517900 val =  0.991150\n",
      "226 Epoch: 0015 cost =  0.032684291 val =  0.991150\n",
      "226 Epoch: 0016 cost =  0.027996584 val =  0.991150\n",
      "226 Epoch: 0017 cost =  0.029580828 val =  0.991150\n",
      "226 Epoch: 0018 cost =  0.026993971 val =  0.991150\n",
      "226 Epoch: 0019 cost =  0.025016183 val =  0.991150\n",
      "226 Epoch: 0020 cost =  0.025125349 val =  0.991150\n",
      "226 Epoch: 0021 cost =  0.024236744 val =  0.991150\n",
      "226 Epoch: 0022 cost =  0.023348449 val =  0.995575\n",
      "226 Epoch: 0023 cost =  0.022976061 val =  0.995575\n",
      "226 Epoch: 0024 cost =  0.022190006 val =  0.995575\n",
      "226 Epoch: 0025 cost =  0.021458624 val =  0.995575\n",
      "226 Epoch: 0026 cost =  0.020961788 val =  0.995575\n",
      "226 Epoch: 0027 cost =  0.020420590 val =  0.995575\n",
      "226 Epoch: 0028 cost =  0.019909447 val =  0.995575\n",
      "226 Epoch: 0029 cost =  0.019392596 val =  0.995575\n",
      "226 Epoch: 0030 cost =  0.018863600 val =  0.995575\n",
      "226 Epoch: 0031 cost =  0.018380255 val =  0.995575\n",
      "226 Epoch: 0032 cost =  0.017928823 val =  0.995575\n",
      "226 Epoch: 0033 cost =  0.017487790 val =  0.995575\n",
      "226 Epoch: 0034 cost =  0.017050208 val =  0.995575\n",
      "226 Epoch: 0035 cost =  0.016600452 val =  0.995575\n",
      "226 Epoch: 0036 cost =  0.016164188 val =  0.995575\n",
      "226 Epoch: 0037 cost =  0.015743547 val =  0.995575\n",
      "226 Epoch: 0038 cost =  0.015334604 val =  0.995575\n",
      "226 Epoch: 0039 cost =  0.014926484 val =  0.995575\n",
      "226 Epoch: 0040 cost =  0.014527259 val =  0.995575\n",
      "226 Epoch: 0041 cost =  0.014127060 val =  0.995575\n",
      "226 Epoch: 0042 cost =  0.013744773 val =  0.995575\n",
      "226 Epoch: 0043 cost =  0.013371308 val =  0.995575\n",
      "226 Epoch: 0044 cost =  0.013000233 val =  0.995575\n",
      "226 Epoch: 0045 cost =  0.012639821 val =  0.995575\n",
      "226 Epoch: 0046 cost =  0.012288656 val =  0.995575\n",
      "226 Epoch: 0047 cost =  0.011940682 val =  0.995575\n",
      "226 Epoch: 0048 cost =  0.011610633 val =  0.995575\n",
      "226 Epoch: 0049 cost =  0.011288995 val =  0.995575\n",
      "226 Epoch: 0050 cost =  0.010976426 val =  0.995575\n",
      "226 Epoch: 0051 cost =  0.010665922 val =  0.995575\n",
      "226 Epoch: 0052 cost =  0.010375183 val =  0.995575\n",
      "226 Epoch: 0053 cost =  0.010085644 val =  0.995575\n",
      "226 Epoch: 0054 cost =  0.009807267 val =  0.995575\n",
      "226 Epoch: 0055 cost =  0.009543469 val =  0.995575\n",
      "226 Epoch: 0056 cost =  0.009298238 val =  0.995575\n",
      "226 Epoch: 0057 cost =  0.009059900 val =  0.995575\n",
      "226 Epoch: 0058 cost =  0.008827790 val =  0.995575\n",
      "226 Epoch: 0059 cost =  0.008605023 val =  0.995575\n",
      "226 Epoch: 0060 cost =  0.008400635 val =  0.995575\n",
      "226 Epoch: 0061 cost =  0.008190357 val =  0.995575\n",
      "226 Epoch: 0062 cost =  0.007984344 val =  0.995575\n",
      "226 Epoch: 0063 cost =  0.007789767 val =  0.995575\n",
      "226 Epoch: 0064 cost =  0.007611440 val =  0.995575\n",
      "226 Epoch: 0065 cost =  0.007420274 val =  0.995575\n",
      "226 Epoch: 0066 cost =  0.007239826 val =  0.995575\n",
      "226 Epoch: 0067 cost =  0.007069331 val =  0.995575\n",
      "226 Epoch: 0068 cost =  0.006901190 val =  0.995575\n",
      "226 Epoch: 0069 cost =  0.006740119 val =  0.995575\n",
      "226 Epoch: 0070 cost =  0.006581110 val =  0.995575\n",
      "226 Epoch: 0071 cost =  0.006431146 val =  0.995575\n",
      "226 Epoch: 0072 cost =  0.006285482 val =  0.995575\n",
      "226 Epoch: 0073 cost =  0.006145584 val =  0.995575\n",
      "226 Epoch: 0074 cost =  0.006004954 val =  0.995575\n",
      "226 Epoch: 0075 cost =  0.005872835 val =  0.995575\n",
      "226 Epoch: 0076 cost =  0.005744145 val =  0.995575\n",
      "226 Epoch: 0077 cost =  0.005621151 val =  0.995575\n",
      "226 Epoch: 0078 cost =  0.005498849 val =  0.995575\n",
      "226 Epoch: 0079 cost =  0.005381389 val =  0.995575\n",
      "226 Epoch: 0080 cost =  0.005271343 val =  0.995575\n",
      "226 Epoch: 0081 cost =  0.005167640 val =  0.995575\n",
      "226 Epoch: 0082 cost =  0.005064538 val =  0.995575\n",
      "226 Epoch: 0083 cost =  0.004966297 val =  0.995575\n",
      "226 Epoch: 0084 cost =  0.004868071 val =  0.995575\n",
      "226 Epoch: 0085 cost =  0.004773109 val =  0.995575\n",
      "226 Epoch: 0086 cost =  0.004681202 val =  0.995575\n",
      "226 Epoch: 0087 cost =  0.004590209 val =  0.995575\n",
      "226 Epoch: 0088 cost =  0.004498036 val =  0.995575\n",
      "226 Epoch: 0089 cost =  0.004411011 val =  0.995575\n",
      "226 Epoch: 0090 cost =  0.004326326 val =  0.995575\n",
      "226 Epoch: 0091 cost =  0.004243943 val =  0.995575\n",
      "226 Epoch: 0092 cost =  0.004162868 val =  0.995575\n",
      "226 Epoch: 0093 cost =  0.004082709 val =  0.995575\n",
      "226 Epoch: 0094 cost =  0.004008728 val =  0.995575\n",
      "226 Epoch: 0095 cost =  0.003931763 val =  0.995575\n",
      "226 Epoch: 0096 cost =  0.003856077 val =  0.995575\n",
      "226 Epoch: 0097 cost =  0.003779935 val =  0.995575\n",
      "226 Epoch: 0098 cost =  0.003707600 val =  0.995575\n",
      "226 Epoch: 0099 cost =  0.003638983 val =  0.995575\n",
      "226 Epoch: 0100 cost =  0.003570572 val =  0.995575\n",
      "226 Epoch: 0101 cost =  0.003505484 val =  0.995575\n",
      "226 Epoch: 0102 cost =  0.003442209 val =  0.995575\n",
      "226 Epoch: 0103 cost =  0.003381531 val =  0.995575\n",
      "226 Epoch: 0104 cost =  0.003321159 val =  0.995575\n",
      "226 Epoch: 0105 cost =  0.003263571 val =  0.995575\n",
      "226 Epoch: 0106 cost =  0.003207534 val =  0.995575\n",
      "226 Epoch: 0107 cost =  0.003151693 val =  0.995575\n",
      "226 Epoch: 0108 cost =  0.003098683 val =  0.995575\n",
      "226 Epoch: 0109 cost =  0.003045081 val =  0.995575\n",
      "226 Epoch: 0110 cost =  0.002993773 val =  0.995575\n",
      "226 Epoch: 0111 cost =  0.002942577 val =  0.995575\n",
      "226 Epoch: 0112 cost =  0.002893414 val =  0.995575\n",
      "226 Epoch: 0113 cost =  0.002844758 val =  0.995575\n",
      "226 Epoch: 0114 cost =  0.002797458 val =  0.995575\n",
      "226 Epoch: 0115 cost =  0.002751956 val =  0.995575\n",
      "226 Epoch: 0116 cost =  0.002708121 val =  0.995575\n",
      "226 Epoch: 0117 cost =  0.002664066 val =  0.995575\n",
      "226 Epoch: 0118 cost =  0.002622365 val =  0.995575\n",
      "226 Epoch: 0119 cost =  0.002582023 val =  0.995575\n",
      "226 Epoch: 0120 cost =  0.002542920 val =  0.995575\n",
      "226 Epoch: 0121 cost =  0.002504257 val =  0.995575\n",
      "226 Epoch: 0122 cost =  0.002466000 val =  0.995575\n",
      "226 Epoch: 0123 cost =  0.002430710 val =  0.995575\n",
      "226 Epoch: 0124 cost =  0.002395031 val =  0.995575\n",
      "226 Epoch: 0125 cost =  0.002359929 val =  0.995575\n",
      "226 Epoch: 0126 cost =  0.002327070 val =  0.995575\n",
      "226 Epoch: 0127 cost =  0.002294029 val =  0.995575\n",
      "226 Epoch: 0128 cost =  0.002261969 val =  0.995575\n",
      "226 Epoch: 0129 cost =  0.002231893 val =  0.995575\n",
      "226 Epoch: 0130 cost =  0.002201446 val =  0.995575\n",
      "226 Epoch: 0131 cost =  0.002171813 val =  0.995575\n",
      "226 Epoch: 0132 cost =  0.002143181 val =  0.995575\n",
      "226 Epoch: 0133 cost =  0.002114840 val =  0.995575\n",
      "226 Epoch: 0134 cost =  0.002087239 val =  0.995575\n",
      "226 Epoch: 0135 cost =  0.002060491 val =  0.995575\n",
      "226 Epoch: 0136 cost =  0.002034376 val =  0.995575\n",
      "226 Epoch: 0137 cost =  0.002008718 val =  0.995575\n",
      "226 Epoch: 0138 cost =  0.001983969 val =  0.995575\n",
      "226 Epoch: 0139 cost =  0.001958945 val =  0.995575\n",
      "226 Epoch: 0140 cost =  0.001933592 val =  0.995575\n",
      "226 Epoch: 0141 cost =  0.001909653 val =  0.995575\n",
      "226 Epoch: 0142 cost =  0.001885636 val =  0.995575\n",
      "226 Epoch: 0143 cost =  0.001861398 val =  0.995575\n",
      "226 Epoch: 0144 cost =  0.001838638 val =  0.995575\n",
      "226 Epoch: 0145 cost =  0.001816886 val =  0.995575\n",
      "226 Epoch: 0146 cost =  0.001794833 val =  0.995575\n",
      "226 Epoch: 0147 cost =  0.001773948 val =  0.995575\n",
      "226 Epoch: 0148 cost =  0.001752805 val =  0.995575\n",
      "226 Epoch: 0149 cost =  0.001731996 val =  0.995575\n",
      "226 Epoch: 0150 cost =  0.001711993 val =  0.995575\n",
      "226 Epoch: 0151 cost =  0.001691860 val =  0.995575\n",
      "226 Epoch: 0152 cost =  0.001672205 val =  0.995575\n",
      "226 Epoch: 0153 cost =  0.001653123 val =  0.995575\n",
      "226 Epoch: 0154 cost =  0.001634148 val =  0.995575\n",
      "226 Epoch: 0155 cost =  0.001615909 val =  0.995575\n",
      "226 Epoch: 0156 cost =  0.001597461 val =  0.995575\n",
      "226 Epoch: 0157 cost =  0.001579518 val =  0.995575\n",
      "226 Epoch: 0158 cost =  0.001561674 val =  0.995575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0159 cost =  0.001544340 val =  0.995575\n",
      "226 Epoch: 0160 cost =  0.001527306 val =  0.995575\n",
      "226 Epoch: 0161 cost =  0.001510677 val =  0.995575\n",
      "226 Epoch: 0162 cost =  0.001493890 val =  0.995575\n",
      "226 Epoch: 0163 cost =  0.001477761 val =  0.995575\n",
      "226 Epoch: 0164 cost =  0.001461346 val =  0.995575\n",
      "226 Epoch: 0165 cost =  0.001445823 val =  0.995575\n",
      "226 Epoch: 0166 cost =  0.001430164 val =  0.995575\n",
      "226 Epoch: 0167 cost =  0.001414722 val =  0.995575\n",
      "226 Epoch: 0168 cost =  0.001399689 val =  0.995575\n",
      "226 Epoch: 0169 cost =  0.001385117 val =  0.995575\n",
      "226 Epoch: 0170 cost =  0.001370271 val =  0.995575\n",
      "226 Epoch: 0171 cost =  0.001355944 val =  0.995575\n",
      "226 Epoch: 0172 cost =  0.001341739 val =  0.995575\n",
      "226 Epoch: 0173 cost =  0.001327538 val =  0.995575\n",
      "226 Epoch: 0174 cost =  0.001313879 val =  0.995575\n",
      "226 Epoch: 0175 cost =  0.001300665 val =  0.995575\n",
      "226 Epoch: 0176 cost =  0.001287144 val =  0.995575\n",
      "226 Epoch: 0177 cost =  0.001273956 val =  0.995575\n",
      "226 Epoch: 0178 cost =  0.001261022 val =  0.995575\n",
      "226 Epoch: 0179 cost =  0.001248244 val =  0.995575\n",
      "226 Epoch: 0180 cost =  0.001235505 val =  0.995575\n",
      "226 Epoch: 0181 cost =  0.001223298 val =  0.995575\n",
      "226 Epoch: 0182 cost =  0.001211212 val =  0.995575\n",
      "226 Epoch: 0183 cost =  0.001199137 val =  0.995575\n",
      "226 Epoch: 0184 cost =  0.001187250 val =  0.995575\n",
      "226 Epoch: 0185 cost =  0.001175687 val =  0.995575\n",
      "226 Epoch: 0186 cost =  0.001164043 val =  0.995575\n",
      "226 Epoch: 0187 cost =  0.001152601 val =  0.995575\n",
      "226 Epoch: 0188 cost =  0.001141447 val =  0.995575\n",
      "226 Epoch: 0189 cost =  0.001130621 val =  0.995575\n",
      "226 Epoch: 0190 cost =  0.001119491 val =  0.995575\n",
      "226 Epoch: 0191 cost =  0.001108761 val =  0.995575\n",
      "226 Epoch: 0192 cost =  0.001098517 val =  0.995575\n",
      "226 Epoch: 0193 cost =  0.001088147 val =  0.995575\n",
      "226 Epoch: 0194 cost =  0.001077581 val =  0.995575\n",
      "226 Epoch: 0195 cost =  0.001067412 val =  0.995575\n",
      "226 Epoch: 0196 cost =  0.001057469 val =  0.995575\n",
      "226 Epoch: 0197 cost =  0.001047702 val =  0.995575\n",
      "226 Epoch: 0198 cost =  0.001037927 val =  0.995575\n",
      "226 Epoch: 0199 cost =  0.001028316 val =  0.995575\n",
      "226 Epoch: 0200 cost =  0.001018777 val =  0.995575\n",
      "226 Epoch: 0201 cost =  0.001009124 val =  0.995575\n",
      "226 Epoch: 0202 cost =  0.001000045 val =  0.995575\n",
      "226 Epoch: 0203 cost =  0.000991284 val =  0.995575\n",
      "226 Epoch: 0204 cost =  0.000982407 val =  0.995575\n",
      "226 Epoch: 0205 cost =  0.000973223 val =  0.995575\n",
      "226 Epoch: 0206 cost =  0.000964510 val =  0.995575\n",
      "226 Epoch: 0207 cost =  0.000956018 val =  0.995575\n",
      "226 Epoch: 0208 cost =  0.000947479 val =  0.995575\n",
      "226 Epoch: 0209 cost =  0.000939320 val =  0.995575\n",
      "226 Epoch: 0210 cost =  0.000930670 val =  0.995575\n",
      "226 Epoch: 0211 cost =  0.000922466 val =  0.995575\n",
      "226 Epoch: 0212 cost =  0.000914558 val =  0.995575\n",
      "226 Epoch: 0213 cost =  0.000906682 val =  0.995575\n",
      "226 Epoch: 0214 cost =  0.000898811 val =  0.995575\n",
      "226 Epoch: 0215 cost =  0.000890743 val =  0.995575\n",
      "226 Epoch: 0216 cost =  0.000883035 val =  0.995575\n",
      "226 Epoch: 0217 cost =  0.000875399 val =  0.995575\n",
      "226 Epoch: 0218 cost =  0.000867716 val =  0.995575\n",
      "226 Epoch: 0219 cost =  0.000860143 val =  0.995575\n",
      "226 Epoch: 0220 cost =  0.000852584 val =  0.995575\n",
      "226 Epoch: 0221 cost =  0.000845302 val =  0.995575\n",
      "226 Epoch: 0222 cost =  0.000838125 val =  0.995575\n",
      "226 Epoch: 0223 cost =  0.000831191 val =  0.995575\n",
      "226 Epoch: 0224 cost =  0.000823836 val =  0.995575\n",
      "226 Epoch: 0225 cost =  0.000816855 val =  0.995575\n",
      "226 Epoch: 0226 cost =  0.000809893 val =  0.995575\n",
      "226 Epoch: 0227 cost =  0.000803197 val =  0.995575\n",
      "226 Epoch: 0228 cost =  0.000796563 val =  0.995575\n",
      "226 Epoch: 0229 cost =  0.000789898 val =  0.995575\n",
      "226 Epoch: 0230 cost =  0.000783356 val =  0.995575\n",
      "226 Epoch: 0231 cost =  0.000777251 val =  0.995575\n",
      "226 Epoch: 0232 cost =  0.000770943 val =  0.995575\n",
      "226 Epoch: 0233 cost =  0.000764492 val =  0.995575\n",
      "226 Epoch: 0234 cost =  0.000758296 val =  0.995575\n",
      "226 Epoch: 0235 cost =  0.000752260 val =  0.995575\n",
      "226 Epoch: 0236 cost =  0.000746152 val =  0.995575\n",
      "226 Epoch: 0237 cost =  0.000740280 val =  0.995575\n",
      "226 Epoch: 0238 cost =  0.000734341 val =  0.995575\n",
      "226 Epoch: 0239 cost =  0.000728356 val =  0.995575\n",
      "226 Epoch: 0240 cost =  0.000722651 val =  0.995575\n",
      "226 Epoch: 0241 cost =  0.000717086 val =  0.995575\n",
      "226 Epoch: 0242 cost =  0.000711511 val =  0.995575\n",
      "226 Epoch: 0243 cost =  0.000705889 val =  0.995575\n",
      "226 Epoch: 0244 cost =  0.000700359 val =  0.995575\n",
      "226 Epoch: 0245 cost =  0.000694868 val =  0.995575\n",
      "226 Epoch: 0246 cost =  0.000689475 val =  0.995575\n",
      "226 Epoch: 0247 cost =  0.000684169 val =  0.995575\n",
      "226 Epoch: 0248 cost =  0.000678825 val =  0.995575\n",
      "226 Epoch: 0249 cost =  0.000673727 val =  0.995575\n",
      "226 Epoch: 0250 cost =  0.000668656 val =  0.995575\n",
      "226 Epoch: 0251 cost =  0.000663631 val =  0.995575\n",
      "226 Epoch: 0252 cost =  0.000658525 val =  0.995575\n",
      "226 Epoch: 0253 cost =  0.000653558 val =  0.995575\n",
      "226 Epoch: 0254 cost =  0.000648526 val =  0.995575\n",
      "226 Epoch: 0255 cost =  0.000643663 val =  0.995575\n",
      "226 Epoch: 0256 cost =  0.000638973 val =  0.995575\n",
      "226 Epoch: 0257 cost =  0.000634226 val =  0.995575\n",
      "226 Epoch: 0258 cost =  0.000629562 val =  0.995575\n",
      "226 Epoch: 0259 cost =  0.000624814 val =  0.995575\n",
      "226 Epoch: 0260 cost =  0.000620132 val =  0.995575\n",
      "226 Epoch: 0261 cost =  0.000615521 val =  0.995575\n",
      "226 Epoch: 0262 cost =  0.000610990 val =  0.995575\n",
      "226 Epoch: 0263 cost =  0.000606574 val =  0.995575\n",
      "226 Epoch: 0264 cost =  0.000602172 val =  0.995575\n",
      "226 Epoch: 0265 cost =  0.000597809 val =  0.995575\n",
      "226 Epoch: 0266 cost =  0.000593485 val =  0.995575\n",
      "226 Epoch: 0267 cost =  0.000589220 val =  0.995575\n",
      "226 Epoch: 0268 cost =  0.000584957 val =  0.995575\n",
      "226 Epoch: 0269 cost =  0.000580553 val =  0.995575\n",
      "226 Epoch: 0270 cost =  0.000576438 val =  0.995575\n",
      "226 Epoch: 0271 cost =  0.000572463 val =  0.995575\n",
      "226 Epoch: 0272 cost =  0.000568457 val =  0.995575\n",
      "226 Epoch: 0273 cost =  0.000564316 val =  0.995575\n",
      "226 Epoch: 0274 cost =  0.000560315 val =  0.995575\n",
      "226 Epoch: 0275 cost =  0.000556297 val =  0.995575\n",
      "226 Epoch: 0276 cost =  0.000552396 val =  0.995575\n",
      "226 Epoch: 0277 cost =  0.000548578 val =  0.995575\n",
      "226 Epoch: 0278 cost =  0.000544793 val =  0.995575\n",
      "226 Epoch: 0279 cost =  0.000541048 val =  0.995575\n",
      "226 Epoch: 0280 cost =  0.000537271 val =  0.995575\n",
      "226 Epoch: 0281 cost =  0.000533485 val =  0.995575\n",
      "226 Epoch: 0282 cost =  0.000529644 val =  0.995575\n",
      "226 Epoch: 0283 cost =  0.000526097 val =  0.995575\n",
      "226 Epoch: 0284 cost =  0.000522589 val =  0.995575\n",
      "226 Epoch: 0285 cost =  0.000519078 val =  0.995575\n",
      "226 Epoch: 0286 cost =  0.000515422 val =  0.995575\n",
      "226 Epoch: 0287 cost =  0.000511851 val =  0.995575\n",
      "226 Epoch: 0288 cost =  0.000508310 val =  0.995575\n",
      "226 Epoch: 0289 cost =  0.000504754 val =  0.995575\n",
      "226 Epoch: 0290 cost =  0.000501396 val =  0.995575\n",
      "226 Epoch: 0291 cost =  0.000498097 val =  0.995575\n",
      "226 Epoch: 0292 cost =  0.000494734 val =  0.995575\n",
      "226 Epoch: 0293 cost =  0.000491329 val =  0.995575\n",
      "226 Epoch: 0294 cost =  0.000487956 val =  0.995575\n",
      "226 Epoch: 0295 cost =  0.000484703 val =  0.995575\n",
      "226 Epoch: 0296 cost =  0.000481584 val =  0.995575\n",
      "226 Epoch: 0297 cost =  0.000478363 val =  0.995575\n",
      "226 Epoch: 0298 cost =  0.000475131 val =  0.995575\n",
      "226 Epoch: 0299 cost =  0.000472029 val =  0.995575\n",
      "226 Epoch: 0300 cost =  0.000468706 val =  0.995575\n",
      "226 Epoch: 0301 cost =  0.000465727 val =  0.995575\n",
      "226 Epoch: 0302 cost =  0.000462723 val =  0.995575\n",
      "226 Epoch: 0303 cost =  0.000459738 val =  0.995575\n",
      "226 Epoch: 0304 cost =  0.000456698 val =  0.995575\n",
      "226 Epoch: 0305 cost =  0.000453532 val =  0.995575\n",
      "226 Epoch: 0306 cost =  0.000450642 val =  0.995575\n",
      "226 Epoch: 0307 cost =  0.000447769 val =  0.995575\n",
      "226 Epoch: 0308 cost =  0.000444892 val =  0.995575\n",
      "226 Epoch: 0309 cost =  0.000441971 val =  0.995575\n",
      "226 Epoch: 0310 cost =  0.000439121 val =  0.995575\n",
      "226 Epoch: 0311 cost =  0.000436184 val =  0.995575\n",
      "226 Epoch: 0312 cost =  0.000433465 val =  0.995575\n",
      "226 Epoch: 0313 cost =  0.000430809 val =  0.995575\n",
      "226 Epoch: 0314 cost =  0.000428075 val =  0.995575\n",
      "226 Epoch: 0315 cost =  0.000425303 val =  0.995575\n",
      "226 Epoch: 0316 cost =  0.000422489 val =  0.995575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0317 cost =  0.000419819 val =  0.995575\n",
      "226 Epoch: 0318 cost =  0.000417307 val =  0.995575\n",
      "226 Epoch: 0319 cost =  0.000414716 val =  0.995575\n",
      "226 Epoch: 0320 cost =  0.000412141 val =  0.995575\n",
      "226 Epoch: 0321 cost =  0.000409408 val =  0.995575\n",
      "226 Epoch: 0322 cost =  0.000406973 val =  0.995575\n",
      "226 Epoch: 0323 cost =  0.000404498 val =  0.995575\n",
      "226 Epoch: 0324 cost =  0.000402000 val =  0.995575\n",
      "226 Epoch: 0325 cost =  0.000399550 val =  0.995575\n",
      "226 Epoch: 0326 cost =  0.000397045 val =  0.995575\n",
      "226 Epoch: 0327 cost =  0.000394651 val =  0.995575\n",
      "226 Epoch: 0328 cost =  0.000392243 val =  0.995575\n",
      "226 Epoch: 0329 cost =  0.000389773 val =  0.995575\n",
      "226 Epoch: 0330 cost =  0.000387507 val =  0.995575\n",
      "226 Epoch: 0331 cost =  0.000385253 val =  0.995575\n",
      "226 Epoch: 0332 cost =  0.000382969 val =  0.995575\n",
      "226 Epoch: 0333 cost =  0.000380509 val =  0.995575\n",
      "226 Epoch: 0334 cost =  0.000378265 val =  0.995575\n",
      "226 Epoch: 0335 cost =  0.000376063 val =  0.995575\n",
      "226 Epoch: 0336 cost =  0.000373857 val =  0.995575\n",
      "226 Epoch: 0337 cost =  0.000371628 val =  0.995575\n",
      "226 Epoch: 0338 cost =  0.000369398 val =  0.995575\n",
      "226 Epoch: 0339 cost =  0.000367181 val =  0.995575\n",
      "226 Epoch: 0340 cost =  0.000364955 val =  0.995575\n",
      "226 Epoch: 0341 cost =  0.000362860 val =  0.995575\n",
      "226 Epoch: 0342 cost =  0.000360786 val =  0.995575\n",
      "226 Epoch: 0343 cost =  0.000358687 val =  0.995575\n",
      "226 Epoch: 0344 cost =  0.000356516 val =  0.995575\n",
      "226 Epoch: 0345 cost =  0.000354402 val =  0.995575\n",
      "226 Epoch: 0346 cost =  0.000352345 val =  0.995575\n",
      "226 Epoch: 0347 cost =  0.000350337 val =  0.995575\n",
      "226 Epoch: 0348 cost =  0.000348341 val =  0.995575\n",
      "226 Epoch: 0349 cost =  0.000346318 val =  0.995575\n",
      "226 Epoch: 0350 cost =  0.000344224 val =  0.995575\n",
      "226 Epoch: 0351 cost =  0.000342281 val =  0.995575\n",
      "226 Epoch: 0352 cost =  0.000340379 val =  0.995575\n",
      "226 Epoch: 0353 cost =  0.000338389 val =  0.995575\n",
      "226 Epoch: 0354 cost =  0.000336455 val =  0.995575\n",
      "226 Epoch: 0355 cost =  0.000334491 val =  0.995575\n",
      "226 Epoch: 0356 cost =  0.000332482 val =  0.995575\n",
      "226 Epoch: 0357 cost =  0.000330678 val =  0.995575\n",
      "226 Epoch: 0358 cost =  0.000328879 val =  0.995575\n",
      "226 Epoch: 0359 cost =  0.000326969 val =  0.995575\n",
      "226 Epoch: 0360 cost =  0.000325122 val =  0.995575\n",
      "226 Epoch: 0361 cost =  0.000323152 val =  0.995575\n",
      "226 Epoch: 0362 cost =  0.000321398 val =  0.995575\n",
      "226 Epoch: 0363 cost =  0.000319625 val =  0.995575\n",
      "226 Epoch: 0364 cost =  0.000317888 val =  0.995575\n",
      "226 Epoch: 0365 cost =  0.000316040 val =  0.995575\n",
      "226 Epoch: 0366 cost =  0.000314166 val =  0.995575\n",
      "226 Epoch: 0367 cost =  0.000312453 val =  0.995575\n",
      "226 Epoch: 0368 cost =  0.000310777 val =  0.995575\n",
      "226 Epoch: 0369 cost =  0.000309076 val =  0.995575\n",
      "226 Epoch: 0370 cost =  0.000307349 val =  0.995575\n",
      "226 Epoch: 0371 cost =  0.000305530 val =  0.995575\n",
      "226 Epoch: 0372 cost =  0.000303846 val =  0.995575\n",
      "226 Epoch: 0373 cost =  0.000302199 val =  0.995575\n",
      "226 Epoch: 0374 cost =  0.000300572 val =  0.995575\n",
      "226 Epoch: 0375 cost =  0.000298929 val =  0.995575\n",
      "226 Epoch: 0376 cost =  0.000297215 val =  0.995575\n",
      "226 Epoch: 0377 cost =  0.000295565 val =  0.995575\n",
      "226 Epoch: 0378 cost =  0.000294007 val =  0.995575\n",
      "226 Epoch: 0379 cost =  0.000292428 val =  0.995575\n",
      "226 Epoch: 0380 cost =  0.000290853 val =  0.995575\n",
      "226 Epoch: 0381 cost =  0.000289206 val =  0.995575\n",
      "226 Epoch: 0382 cost =  0.000287623 val =  0.995575\n",
      "226 Epoch: 0383 cost =  0.000286102 val =  0.995575\n",
      "226 Epoch: 0384 cost =  0.000284608 val =  0.995575\n",
      "226 Epoch: 0385 cost =  0.000283087 val =  0.995575\n",
      "226 Epoch: 0386 cost =  0.000281508 val =  0.995575\n",
      "226 Epoch: 0387 cost =  0.000279977 val =  0.995575\n",
      "226 Epoch: 0388 cost =  0.000278560 val =  0.995575\n",
      "226 Epoch: 0389 cost =  0.000277066 val =  0.995575\n",
      "226 Epoch: 0390 cost =  0.000275528 val =  0.995575\n",
      "226 Epoch: 0391 cost =  0.000274113 val =  0.995575\n",
      "226 Epoch: 0392 cost =  0.000272674 val =  0.995575\n",
      "226 Epoch: 0393 cost =  0.000271227 val =  0.995575\n",
      "226 Epoch: 0394 cost =  0.000269715 val =  0.995575\n",
      "226 Epoch: 0395 cost =  0.000268327 val =  0.995575\n",
      "226 Epoch: 0396 cost =  0.000266952 val =  0.995575\n",
      "226 Epoch: 0397 cost =  0.000265596 val =  0.995575\n",
      "226 Epoch: 0398 cost =  0.000264172 val =  0.995575\n",
      "226 Epoch: 0399 cost =  0.000262666 val =  0.995575\n",
      "226 Epoch: 0400 cost =  0.000261335 val =  0.995575\n",
      "226 Epoch: 0401 cost =  0.000260038 val =  0.995575\n",
      "226 Epoch: 0402 cost =  0.000258726 val =  0.995575\n",
      "226 Epoch: 0403 cost =  0.000257252 val =  0.995575\n",
      "226 Epoch: 0404 cost =  0.000255962 val =  0.995575\n",
      "226 Epoch: 0405 cost =  0.000254667 val =  0.995575\n",
      "226 Epoch: 0406 cost =  0.000253347 val =  0.995575\n",
      "226 Epoch: 0407 cost =  0.000251939 val =  0.995575\n",
      "226 Epoch: 0408 cost =  0.000250729 val =  0.995575\n",
      "226 Epoch: 0409 cost =  0.000249457 val =  0.995575\n",
      "226 Epoch: 0410 cost =  0.000248171 val =  0.995575\n",
      "226 Epoch: 0411 cost =  0.000246855 val =  0.995575\n",
      "226 Epoch: 0412 cost =  0.000245543 val =  0.995575\n",
      "226 Epoch: 0413 cost =  0.000244295 val =  0.995575\n",
      "226 Epoch: 0414 cost =  0.000243140 val =  0.995575\n",
      "226 Epoch: 0415 cost =  0.000241873 val =  0.995575\n",
      "226 Epoch: 0416 cost =  0.000240573 val =  0.995575\n",
      "226 Epoch: 0417 cost =  0.000239348 val =  0.995575\n",
      "226 Epoch: 0418 cost =  0.000238211 val =  0.995575\n",
      "226 Epoch: 0419 cost =  0.000236947 val =  0.995575\n",
      "226 Epoch: 0420 cost =  0.000235753 val =  0.995575\n",
      "226 Epoch: 0421 cost =  0.000234595 val =  0.995575\n",
      "226 Epoch: 0422 cost =  0.000233377 val =  0.995575\n",
      "226 Epoch: 0423 cost =  0.000232155 val =  0.995575\n",
      "226 Epoch: 0424 cost =  0.000231012 val =  0.995575\n",
      "226 Epoch: 0425 cost =  0.000229890 val =  0.995575\n",
      "226 Epoch: 0426 cost =  0.000228756 val =  0.995575\n",
      "226 Epoch: 0427 cost =  0.000227596 val =  0.995575\n",
      "226 Epoch: 0428 cost =  0.000226395 val =  0.995575\n",
      "226 Epoch: 0429 cost =  0.000225278 val =  0.995575\n",
      "226 Epoch: 0430 cost =  0.000224172 val =  0.995575\n",
      "226 Epoch: 0431 cost =  0.000223082 val =  0.995575\n",
      "226 Epoch: 0432 cost =  0.000221947 val =  0.995575\n",
      "226 Epoch: 0433 cost =  0.000220873 val =  0.995575\n",
      "226 Epoch: 0434 cost =  0.000219771 val =  0.995575\n",
      "226 Epoch: 0435 cost =  0.000218642 val =  0.995575\n",
      "226 Epoch: 0436 cost =  0.000217585 val =  0.995575\n",
      "226 Epoch: 0437 cost =  0.000216556 val =  0.995575\n",
      "226 Epoch: 0438 cost =  0.000215488 val =  0.995575\n",
      "226 Epoch: 0439 cost =  0.000214358 val =  0.995575\n",
      "226 Epoch: 0440 cost =  0.000213314 val =  0.995575\n",
      "226 Epoch: 0441 cost =  0.000212333 val =  0.995575\n",
      "226 Epoch: 0442 cost =  0.000211276 val =  0.995575\n",
      "226 Epoch: 0443 cost =  0.000210206 val =  0.995575\n",
      "226 Epoch: 0444 cost =  0.000209194 val =  0.995575\n",
      "226 Epoch: 0445 cost =  0.000208185 val =  0.995575\n",
      "226 Epoch: 0446 cost =  0.000207198 val =  0.995575\n",
      "226 Epoch: 0447 cost =  0.000206176 val =  0.995575\n",
      "226 Epoch: 0448 cost =  0.000205161 val =  0.995575\n",
      "226 Epoch: 0449 cost =  0.000204189 val =  0.995575\n",
      "226 Epoch: 0450 cost =  0.000203204 val =  0.995575\n",
      "226 Epoch: 0451 cost =  0.000202177 val =  0.995575\n",
      "226 Epoch: 0452 cost =  0.000201237 val =  0.995575\n",
      "226 Epoch: 0453 cost =  0.000200299 val =  0.995575\n",
      "226 Epoch: 0454 cost =  0.000199318 val =  0.995575\n",
      "226 Epoch: 0455 cost =  0.000198305 val =  0.995575\n",
      "226 Epoch: 0456 cost =  0.000197374 val =  0.995575\n",
      "226 Epoch: 0457 cost =  0.000196474 val =  0.995575\n",
      "226 Epoch: 0458 cost =  0.000195571 val =  0.995575\n",
      "226 Epoch: 0459 cost =  0.000194565 val =  0.995575\n",
      "226 Epoch: 0460 cost =  0.000193632 val =  0.995575\n",
      "226 Epoch: 0461 cost =  0.000192736 val =  0.995575\n",
      "226 Epoch: 0462 cost =  0.000191861 val =  0.995575\n",
      "226 Epoch: 0463 cost =  0.000190884 val =  0.995575\n",
      "226 Epoch: 0464 cost =  0.000189981 val =  0.995575\n",
      "226 Epoch: 0465 cost =  0.000189133 val =  0.995575\n",
      "226 Epoch: 0466 cost =  0.000188212 val =  0.995575\n",
      "226 Epoch: 0467 cost =  0.000187314 val =  0.995575\n",
      "226 Epoch: 0468 cost =  0.000186459 val =  0.995575\n",
      "226 Epoch: 0469 cost =  0.000185589 val =  0.995575\n",
      "226 Epoch: 0470 cost =  0.000184670 val =  0.995575\n",
      "226 Epoch: 0471 cost =  0.000183786 val =  0.995575\n",
      "226 Epoch: 0472 cost =  0.000182978 val =  0.995575\n",
      "226 Epoch: 0473 cost =  0.000182119 val =  0.995575\n",
      "226 Epoch: 0474 cost =  0.000181216 val =  0.995575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0475 cost =  0.000180388 val =  0.995575\n",
      "226 Epoch: 0476 cost =  0.000179576 val =  0.995575\n",
      "226 Epoch: 0477 cost =  0.000178765 val =  0.995575\n",
      "226 Epoch: 0478 cost =  0.000177880 val =  0.995575\n",
      "226 Epoch: 0479 cost =  0.000177063 val =  0.995575\n",
      "226 Epoch: 0480 cost =  0.000176276 val =  0.995575\n",
      "226 Epoch: 0481 cost =  0.000175470 val =  0.995575\n",
      "226 Epoch: 0482 cost =  0.000174629 val =  0.995575\n",
      "226 Epoch: 0483 cost =  0.000173823 val =  0.995575\n",
      "226 Epoch: 0484 cost =  0.000173035 val =  0.995575\n",
      "226 Epoch: 0485 cost =  0.000172245 val =  0.995575\n",
      "226 Epoch: 0486 cost =  0.000171430 val =  0.995575\n",
      "226 Epoch: 0487 cost =  0.000170648 val =  0.995575\n",
      "226 Epoch: 0488 cost =  0.000169885 val =  0.995575\n",
      "226 Epoch: 0489 cost =  0.000169106 val =  0.995575\n",
      "226 Epoch: 0490 cost =  0.000168299 val =  0.995575\n",
      "226 Epoch: 0491 cost =  0.000167557 val =  0.995575\n",
      "226 Epoch: 0492 cost =  0.000166801 val =  0.995575\n",
      "226 Epoch: 0493 cost =  0.000166024 val =  0.995575\n",
      "226 Epoch: 0494 cost =  0.000165273 val =  0.995575\n",
      "226 Epoch: 0495 cost =  0.000164553 val =  0.995575\n",
      "226 Epoch: 0496 cost =  0.000163776 val =  0.995575\n",
      "226 Epoch: 0497 cost =  0.000163053 val =  0.995575\n",
      "226 Epoch: 0498 cost =  0.000162322 val =  0.995575\n",
      "226 Epoch: 0499 cost =  0.000161587 val =  0.995575\n",
      "226 Epoch: 0500 cost =  0.000160826 val =  0.995575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../model/CNN/cnn_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "batch_size = 256\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "\n",
    "for epoch in range(training_epochs):#training epoch 500 / batch_size 128 --> acc 90%\n",
    "    avg_cost = 0\n",
    "    val_avg_cost =0\n",
    "    total_batch = int(y_train.shape[0] / batch_size)\n",
    "    for i in range(0, y_train.shape[0], batch_size):\n",
    "        feed_dict={X:X_train2[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "        avg_cost += c/total_batch \n",
    "    \n",
    "    y_pred = sess.run(logits, feed_dict={X:X_val2})\n",
    "    y_pred = sess.run(tf.argmax(y_pred,1))\n",
    "    y_true = y_val\n",
    "        \n",
    "    y_true = sess.run(tf.argmax(y_true,1))\n",
    "    print(len(y_pred),end=' ')\n",
    "    print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost), 'val = ','%f' %(accuracy_score(y_true, y_pred)) )\n",
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.996\n",
      "Accuracy:  0.9964539007092199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       134\n",
      "           1       1.00      0.99      1.00       148\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       282\n",
      "   macro avg       1.00      1.00      1.00       282\n",
      "weighted avg       1.00      1.00      1.00       282\n",
      "\n",
      "[[134   0]\n",
      " [  1 147]]\n"
     ]
    }
   ],
   "source": [
    "# Print Result\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

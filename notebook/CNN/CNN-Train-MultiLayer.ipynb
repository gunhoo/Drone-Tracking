{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have been save the data, you don't have to preprocessing and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_path = '../../data/drone/*.wav'\n",
    "background_path = '../../data/background-tmp/*.wav'\n",
    "\n",
    "drone_files = glob.glob(drone_path)\n",
    "background_files = glob.glob(background_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 22050\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=22050):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11406619,)\n",
      "(11127941,)\n"
     ]
    }
   ],
   "source": [
    "drone_raw = load(drone_files)\n",
    "background_raw = load(background_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=22050, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11406619,)\n",
      "small end: (16, 15)\n",
      "small end: (16, 7)\n",
      "(11127941,)\n",
      "small end: (16, 15)\n",
      "small end: (16, 7)\n",
      "(2783, 16, 16) (2783,)\n",
      "(2715, 16, 16) (2715,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_drone, y_drone = mfcc4(drone_raw, 1)\n",
    "mfcc_background, y_background = mfcc4(background_raw, 0)\n",
    "\n",
    "print(mfcc_drone.shape, y_drone.shape)\n",
    "print(mfcc_background.shape, y_background.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5498, 16, 16) (5498,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_drone, mfcc_background), axis=0)\n",
    "#X = np.concatenate((mfcc_drone), axis=0)\n",
    "#X = X.reshape(-1, 16,16,1)\n",
    "y = np.hstack((y_drone, y_background))\n",
    "#y = np.hstack(y_drone)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5498, 2)\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3518, 16, 16) (1100, 16, 16)\n",
      "(880, 16, 16) (880, 2)\n",
      "(3518, 2) (1100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save('../../data/X_train', X_train)\n",
    "np.save('../../data/X_test', X_test)\n",
    "np.save('../../data/X_val', X_val)\n",
    "np.save('../../data/y_val', y_val)\n",
    "np.save('../../data/y_train', y_train)\n",
    "np.save('../../data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load('../../data/X_train.npy')\n",
    "X_test = np.load('../../data/X_test.npy')\n",
    "X_val = np.load('../../data/X_val.npy')\n",
    "y_val = np.load('../../data/y_val.npy')\n",
    "y_train = np.load('../../data/y_train.npy')\n",
    "y_test = np.load('../../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - One convolutional layer /w no dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Experiment 3-2\n",
    "- learning rate 0.005\n",
    "- pooling stride 1x1\n",
    "- #filter 1\n",
    "- best result among every other settings\n",
    "- cost kept fluctuated during training. (0.8 -> 1.3) -- why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.0002  # 0.005\n",
    "training_epochs = 200 # 수정해봐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# dropout넣어야하나\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# 여기도\n",
    "flat = tf.reshape(pool2, [-1, 16*16*1])\n",
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_val2 = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model_path = '../../model/CNN/cnn_model'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880 Epoch: 0001 cost =  0.882419200 val =  0.968182\n",
      "880 Epoch: 0002 cost =  0.196591294 val =  0.969318\n",
      "880 Epoch: 0003 cost =  0.161796901 val =  0.972727\n",
      "880 Epoch: 0004 cost =  0.140712265 val =  0.972727\n",
      "880 Epoch: 0005 cost =  0.127785777 val =  0.976136\n",
      "880 Epoch: 0006 cost =  0.124499973 val =  0.967045\n",
      "880 Epoch: 0007 cost =  0.123583314 val =  0.972727\n",
      "880 Epoch: 0008 cost =  0.107945074 val =  0.973864\n",
      "880 Epoch: 0009 cost =  0.095082831 val =  0.973864\n",
      "880 Epoch: 0010 cost =  0.086398893 val =  0.975000\n",
      "880 Epoch: 0011 cost =  0.075832051 val =  0.970455\n",
      "880 Epoch: 0012 cost =  0.084189737 val =  0.959091\n",
      "880 Epoch: 0013 cost =  0.078910422 val =  0.971591\n",
      "880 Epoch: 0014 cost =  0.070348343 val =  0.960227\n",
      "880 Epoch: 0015 cost =  0.072706838 val =  0.946591\n",
      "880 Epoch: 0016 cost =  0.096965130 val =  0.950000\n",
      "880 Epoch: 0017 cost =  0.221138989 val =  0.981818\n",
      "880 Epoch: 0018 cost =  0.116964159 val =  0.981818\n",
      "880 Epoch: 0019 cost =  0.066181420 val =  0.984091\n",
      "880 Epoch: 0020 cost =  0.050144299 val =  0.981818\n",
      "880 Epoch: 0021 cost =  0.049892885 val =  0.981818\n",
      "880 Epoch: 0022 cost =  0.039064254 val =  0.982955\n",
      "880 Epoch: 0023 cost =  0.033783788 val =  0.985227\n",
      "880 Epoch: 0024 cost =  0.029382685 val =  0.984091\n",
      "880 Epoch: 0025 cost =  0.031662230 val =  0.982955\n",
      "880 Epoch: 0026 cost =  0.029348963 val =  0.981818\n",
      "880 Epoch: 0027 cost =  0.030860777 val =  0.984091\n",
      "880 Epoch: 0028 cost =  0.030411339 val =  0.982955\n",
      "880 Epoch: 0029 cost =  0.029102901 val =  0.980682\n",
      "880 Epoch: 0030 cost =  0.042669976 val =  0.970455\n",
      "880 Epoch: 0031 cost =  0.033933881 val =  0.985227\n",
      "880 Epoch: 0032 cost =  0.039562433 val =  0.987500\n",
      "880 Epoch: 0033 cost =  0.028772357 val =  0.984091\n",
      "880 Epoch: 0034 cost =  0.075909438 val =  0.953409\n",
      "880 Epoch: 0035 cost =  0.036916619 val =  0.984091\n",
      "880 Epoch: 0036 cost =  0.027942324 val =  0.985227\n",
      "880 Epoch: 0037 cost =  0.040094991 val =  0.986364\n",
      "880 Epoch: 0038 cost =  0.031642431 val =  0.984091\n",
      "880 Epoch: 0039 cost =  0.027169332 val =  0.984091\n",
      "880 Epoch: 0040 cost =  0.026604826 val =  0.985227\n",
      "880 Epoch: 0041 cost =  0.024085213 val =  0.985227\n",
      "880 Epoch: 0042 cost =  0.037105992 val =  0.981818\n",
      "880 Epoch: 0043 cost =  0.017347866 val =  0.985227\n",
      "880 Epoch: 0044 cost =  0.022522700 val =  0.971591\n",
      "880 Epoch: 0045 cost =  0.026783861 val =  0.977273\n",
      "880 Epoch: 0046 cost =  0.029600247 val =  0.985227\n",
      "880 Epoch: 0047 cost =  0.022525578 val =  0.979545\n",
      "880 Epoch: 0048 cost =  0.029009818 val =  0.972727\n",
      "880 Epoch: 0049 cost =  0.018507402 val =  0.982955\n",
      "880 Epoch: 0050 cost =  0.016742837 val =  0.972727\n",
      "880 Epoch: 0051 cost =  0.027285208 val =  0.960227\n",
      "880 Epoch: 0052 cost =  0.053220134 val =  0.987500\n",
      "880 Epoch: 0053 cost =  0.037127844 val =  0.967045\n",
      "880 Epoch: 0054 cost =  0.024505064 val =  0.984091\n",
      "880 Epoch: 0055 cost =  0.030709617 val =  0.978409\n",
      "880 Epoch: 0056 cost =  0.032732711 val =  0.979545\n",
      "880 Epoch: 0057 cost =  0.043080905 val =  0.982955\n",
      "880 Epoch: 0058 cost =  0.038295147 val =  0.981818\n",
      "880 Epoch: 0059 cost =  0.029054235 val =  0.982955\n",
      "880 Epoch: 0060 cost =  0.027496868 val =  0.984091\n",
      "880 Epoch: 0061 cost =  0.033764067 val =  0.985227\n",
      "880 Epoch: 0062 cost =  0.039797002 val =  0.986364\n",
      "880 Epoch: 0063 cost =  0.029779095 val =  0.984091\n",
      "880 Epoch: 0064 cost =  0.037004501 val =  0.986364\n",
      "880 Epoch: 0065 cost =  0.023622223 val =  0.985227\n",
      "880 Epoch: 0066 cost =  0.027818438 val =  0.982955\n",
      "880 Epoch: 0067 cost =  0.025088163 val =  0.986364\n",
      "880 Epoch: 0068 cost =  0.029487088 val =  0.986364\n",
      "880 Epoch: 0069 cost =  0.027366214 val =  0.985227\n",
      "880 Epoch: 0070 cost =  0.032833241 val =  0.984091\n",
      "880 Epoch: 0071 cost =  0.024630031 val =  0.977273\n",
      "880 Epoch: 0072 cost =  0.026484485 val =  0.980682\n",
      "880 Epoch: 0073 cost =  0.027084903 val =  0.979545\n",
      "880 Epoch: 0074 cost =  0.036615162 val =  0.984091\n",
      "880 Epoch: 0075 cost =  0.024267219 val =  0.977273\n",
      "880 Epoch: 0076 cost =  0.029984979 val =  0.967045\n",
      "880 Epoch: 0077 cost =  0.039296166 val =  0.987500\n",
      "880 Epoch: 0078 cost =  0.025469320 val =  0.967045\n",
      "880 Epoch: 0079 cost =  0.026274551 val =  0.981818\n",
      "880 Epoch: 0080 cost =  0.014407937 val =  0.981818\n",
      "880 Epoch: 0081 cost =  0.025869819 val =  0.985227\n",
      "880 Epoch: 0082 cost =  0.012542765 val =  0.972727\n",
      "880 Epoch: 0083 cost =  0.016589786 val =  0.967045\n",
      "880 Epoch: 0084 cost =  0.022727131 val =  0.963636\n",
      "880 Epoch: 0085 cost =  0.031314502 val =  0.962500\n",
      "880 Epoch: 0086 cost =  0.034352401 val =  0.982955\n",
      "880 Epoch: 0087 cost =  0.025683310 val =  0.981818\n",
      "880 Epoch: 0088 cost =  0.023794045 val =  0.981818\n",
      "880 Epoch: 0089 cost =  0.019111908 val =  0.986364\n",
      "880 Epoch: 0090 cost =  0.016717944 val =  0.984091\n",
      "880 Epoch: 0091 cost =  0.014523369 val =  0.988636\n",
      "880 Epoch: 0092 cost =  0.015422944 val =  0.984091\n",
      "880 Epoch: 0093 cost =  0.013902092 val =  0.979545\n",
      "880 Epoch: 0094 cost =  0.017709095 val =  0.984091\n",
      "880 Epoch: 0095 cost =  0.011810973 val =  0.984091\n",
      "880 Epoch: 0096 cost =  0.011479342 val =  0.981818\n",
      "880 Epoch: 0097 cost =  0.013106427 val =  0.981818\n",
      "880 Epoch: 0098 cost =  0.016421369 val =  0.984091\n",
      "880 Epoch: 0099 cost =  0.012783816 val =  0.984091\n",
      "880 Epoch: 0100 cost =  0.006903736 val =  0.984091\n",
      "880 Epoch: 0101 cost =  0.009742717 val =  0.987500\n",
      "880 Epoch: 0102 cost =  0.008430510 val =  0.987500\n",
      "880 Epoch: 0103 cost =  0.004807228 val =  0.982955\n",
      "880 Epoch: 0104 cost =  0.003847108 val =  0.982955\n",
      "880 Epoch: 0105 cost =  0.004289083 val =  0.982955\n",
      "880 Epoch: 0106 cost =  0.003268262 val =  0.982955\n",
      "880 Epoch: 0107 cost =  0.003412190 val =  0.981818\n",
      "880 Epoch: 0108 cost =  0.002796282 val =  0.982955\n",
      "880 Epoch: 0109 cost =  0.002273202 val =  0.981818\n",
      "880 Epoch: 0110 cost =  0.002120322 val =  0.982955\n",
      "880 Epoch: 0111 cost =  0.003065919 val =  0.979545\n",
      "880 Epoch: 0112 cost =  0.001834987 val =  0.979545\n",
      "880 Epoch: 0113 cost =  0.001476023 val =  0.981818\n",
      "880 Epoch: 0114 cost =  0.001002743 val =  0.981818\n",
      "880 Epoch: 0115 cost =  0.000989656 val =  0.982955\n",
      "880 Epoch: 0116 cost =  0.001032262 val =  0.980682\n",
      "880 Epoch: 0117 cost =  0.000827150 val =  0.981818\n",
      "880 Epoch: 0118 cost =  0.000987423 val =  0.980682\n",
      "880 Epoch: 0119 cost =  0.001110915 val =  0.978409\n",
      "880 Epoch: 0120 cost =  0.042682879 val =  0.970455\n",
      "880 Epoch: 0121 cost =  0.023201105 val =  0.980682\n",
      "880 Epoch: 0122 cost =  0.002114702 val =  0.982955\n",
      "880 Epoch: 0123 cost =  0.001554898 val =  0.981818\n",
      "880 Epoch: 0124 cost =  0.002070449 val =  0.981818\n",
      "880 Epoch: 0125 cost =  0.001932177 val =  0.981818\n",
      "880 Epoch: 0126 cost =  0.001714365 val =  0.981818\n",
      "880 Epoch: 0127 cost =  0.001690321 val =  0.981818\n",
      "880 Epoch: 0128 cost =  0.001424163 val =  0.978409\n",
      "880 Epoch: 0129 cost =  0.001504595 val =  0.985227\n",
      "880 Epoch: 0130 cost =  0.004202712 val =  0.973864\n",
      "880 Epoch: 0131 cost =  0.017795411 val =  0.985227\n",
      "880 Epoch: 0132 cost =  0.004063246 val =  0.979545\n",
      "880 Epoch: 0133 cost =  0.004775011 val =  0.985227\n",
      "880 Epoch: 0134 cost =  0.004214737 val =  0.984091\n",
      "880 Epoch: 0135 cost =  0.005390811 val =  0.975000\n",
      "880 Epoch: 0136 cost =  0.005076921 val =  0.981818\n",
      "880 Epoch: 0137 cost =  0.006925541 val =  0.984091\n",
      "880 Epoch: 0138 cost =  0.007455352 val =  0.984091\n",
      "880 Epoch: 0139 cost =  0.018100523 val =  0.987500\n",
      "880 Epoch: 0140 cost =  0.009532632 val =  0.984091\n",
      "880 Epoch: 0141 cost =  0.006963152 val =  0.969318\n",
      "880 Epoch: 0142 cost =  0.010877924 val =  0.982955\n",
      "880 Epoch: 0143 cost =  0.009970300 val =  0.986364\n",
      "880 Epoch: 0144 cost =  0.012233802 val =  0.982955\n",
      "880 Epoch: 0145 cost =  0.008211038 val =  0.984091\n",
      "880 Epoch: 0146 cost =  0.004832313 val =  0.986364\n",
      "880 Epoch: 0147 cost =  0.004985913 val =  0.979545\n",
      "880 Epoch: 0148 cost =  0.003159170 val =  0.982955\n",
      "880 Epoch: 0149 cost =  0.007090621 val =  0.987500\n",
      "880 Epoch: 0150 cost =  0.006459932 val =  0.985227\n",
      "880 Epoch: 0151 cost =  0.006311982 val =  0.985227\n",
      "880 Epoch: 0152 cost =  0.006034373 val =  0.986364\n",
      "880 Epoch: 0153 cost =  0.003161428 val =  0.985227\n",
      "880 Epoch: 0154 cost =  0.004094540 val =  0.985227\n",
      "880 Epoch: 0155 cost =  0.003185755 val =  0.982955\n",
      "880 Epoch: 0156 cost =  0.017514917 val =  0.987500\n",
      "880 Epoch: 0157 cost =  0.005898427 val =  0.980682\n",
      "880 Epoch: 0158 cost =  0.005898340 val =  0.985227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880 Epoch: 0159 cost =  0.009384704 val =  0.981818\n",
      "880 Epoch: 0160 cost =  0.003731987 val =  0.985227\n",
      "880 Epoch: 0161 cost =  0.004610961 val =  0.982955\n",
      "880 Epoch: 0162 cost =  0.003380247 val =  0.981818\n",
      "880 Epoch: 0163 cost =  0.003491379 val =  0.984091\n",
      "880 Epoch: 0164 cost =  0.006443148 val =  0.982955\n",
      "880 Epoch: 0165 cost =  0.003188341 val =  0.977273\n",
      "880 Epoch: 0166 cost =  0.003766948 val =  0.981818\n",
      "880 Epoch: 0167 cost =  0.002870603 val =  0.986364\n",
      "880 Epoch: 0168 cost =  0.004875846 val =  0.986364\n",
      "880 Epoch: 0169 cost =  0.003136263 val =  0.977273\n",
      "880 Epoch: 0170 cost =  0.003302423 val =  0.984091\n",
      "880 Epoch: 0171 cost =  0.004043895 val =  0.977273\n",
      "880 Epoch: 0172 cost =  0.002197640 val =  0.981818\n",
      "880 Epoch: 0173 cost =  0.001704386 val =  0.981818\n",
      "880 Epoch: 0174 cost =  0.001988056 val =  0.980682\n",
      "880 Epoch: 0175 cost =  0.004728274 val =  0.982955\n",
      "880 Epoch: 0176 cost =  0.001258940 val =  0.982955\n",
      "880 Epoch: 0177 cost =  0.000812147 val =  0.986364\n",
      "880 Epoch: 0178 cost =  0.000916339 val =  0.985227\n",
      "880 Epoch: 0179 cost =  0.000670929 val =  0.987500\n",
      "880 Epoch: 0180 cost =  0.001133556 val =  0.984091\n",
      "880 Epoch: 0181 cost =  0.001236170 val =  0.985227\n",
      "880 Epoch: 0182 cost =  0.011221669 val =  0.976136\n",
      "880 Epoch: 0183 cost =  0.003807544 val =  0.985227\n",
      "880 Epoch: 0184 cost =  0.004112309 val =  0.984091\n",
      "880 Epoch: 0185 cost =  0.001300699 val =  0.984091\n",
      "880 Epoch: 0186 cost =  0.000802659 val =  0.986364\n",
      "880 Epoch: 0187 cost =  0.000300802 val =  0.985227\n",
      "880 Epoch: 0188 cost =  0.000435004 val =  0.986364\n",
      "880 Epoch: 0189 cost =  0.000181225 val =  0.986364\n",
      "880 Epoch: 0190 cost =  0.000202366 val =  0.985227\n",
      "880 Epoch: 0191 cost =  0.000208912 val =  0.985227\n",
      "880 Epoch: 0192 cost =  0.000182629 val =  0.985227\n",
      "880 Epoch: 0193 cost =  0.000163237 val =  0.985227\n",
      "880 Epoch: 0194 cost =  0.000151827 val =  0.986364\n",
      "880 Epoch: 0195 cost =  0.000137097 val =  0.985227\n",
      "880 Epoch: 0196 cost =  0.000129758 val =  0.985227\n",
      "880 Epoch: 0197 cost =  0.000115700 val =  0.985227\n",
      "880 Epoch: 0198 cost =  0.000109756 val =  0.985227\n",
      "880 Epoch: 0199 cost =  0.000102105 val =  0.985227\n",
      "880 Epoch: 0200 cost =  0.000096861 val =  0.985227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../model/CNN/cnn_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "batch_size = 32\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for epoch in range(training_epochs):#training epoch 500 / batch_size 128 --> acc 90%\n",
    "        avg_cost = 0\n",
    "        val_avg_cost =0\n",
    "        total_batch = int(y_train.shape[0] / batch_size)\n",
    "        for i in range(0, y_train.shape[0], batch_size):\n",
    "            feed_dict={X:X_train2[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "            cost_history = np.append(cost_history,cost)\n",
    "            avg_cost += c/total_batch \n",
    "\n",
    "        y_pred = sess.run(logits, feed_dict={X:X_val2})\n",
    "        y_pred = sess.run(tf.argmax(y_pred,1))\n",
    "        y_true = y_val\n",
    "\n",
    "        y_true = sess.run(tf.argmax(y_true,1))\n",
    "        print(len(y_pred),end=' ')\n",
    "        print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost), 'val = ','%f' %(accuracy_score(y_true, y_pred)) )\n",
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.987\n",
      "Accuracy:  0.9872727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       517\n",
      "           1       0.99      0.99      0.99       583\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1100\n",
      "   macro avg       0.99      0.99      0.99      1100\n",
      "weighted avg       0.99      0.99      0.99      1100\n",
      "\n",
      "[[510   7]\n",
      " [  7 576]]\n"
     ]
    }
   ],
   "source": [
    "# Print Result\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have been save the data, you don't have to preprocessing and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_path = '../../data/drone/*.wav'\n",
    "background_path = '../../data/background/*.wav'\n",
    "\n",
    "drone_files = glob.glob(drone_path)\n",
    "background_files = glob.glob(background_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 44100\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192000,)\n",
      "(5437727,)\n"
     ]
    }
   ],
   "source": [
    "drone_raw = load(drone_files)\n",
    "background_raw = load(background_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=44100, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192000,)\n",
      "small end: (16, 9)\n",
      "(5437727,)\n",
      "small end: (16, 13)\n",
      "small end: (16, 5)\n",
      "(1999, 16, 16) (1999,)\n",
      "(1326, 16, 16) (1326,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_drone, y_drone = mfcc4(drone_raw, 1)\n",
    "mfcc_background, y_background = mfcc4(background_raw, 0)\n",
    "\n",
    "print(mfcc_drone.shape, y_drone.shape)\n",
    "print(mfcc_background.shape, y_background.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3325, 16, 16) (3325,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_drone, mfcc_background), axis=0)\n",
    "#X = np.concatenate((mfcc_drone), axis=0)\n",
    "#X = X.reshape(-1, 16,16,1)\n",
    "y = np.hstack((y_drone, y_background))\n",
    "#y = np.hstack(y_drone)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3325, 2)\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2128, 16, 16) (665, 16, 16)\n",
      "(532, 16, 16) (532, 2)\n",
      "(2128, 2) (665, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save('../../data/X_train', X_train)\n",
    "np.save('../../data/X_test', X_test)\n",
    "np.save('../../model/X_val', X_val)\n",
    "np.save('../../model/y_val', y_val)\n",
    "np.save('../../data/y_train', y_train)\n",
    "np.save('../../data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load('../../data/X_train.npy')\n",
    "X_test = np.load('../../data/X_test.npy')\n",
    "X_val = np.load('../../model/X_val.npy')\n",
    "y_val = np.load('../../model/y_val.npy')\n",
    "y_train = np.load('../../data/y_train.npy')\n",
    "y_test = np.load('../../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - One convolutional layer /w no dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Experiment 3-2\n",
    "- learning rate 0.005\n",
    "- pooling stride 1x1\n",
    "- #filter 1\n",
    "- best result among every other settings\n",
    "- cost kept fluctuated during training. (0.8 -> 1.3) -- why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.0002  # 0.005\n",
    "training_epochs = 500 # 수정해봐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# dropout넣어야하나\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# 여기도\n",
    "flat = tf.reshape(pool2, [-1, 16*16*1])\n",
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_val2 = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model_path = '../../model/CNN/cnn_model'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 Epoch: 0001 cost =  0.693679819 val =  0.573308\n",
      "532 Epoch: 0002 cost =  0.660810842 val =  0.573308\n",
      "532 Epoch: 0003 cost =  0.596134291 val =  0.593985\n",
      "532 Epoch: 0004 cost =  0.498720264 val =  0.780075\n",
      "532 Epoch: 0005 cost =  0.396641511 val =  0.840226\n",
      "532 Epoch: 0006 cost =  0.321399476 val =  0.877820\n",
      "532 Epoch: 0007 cost =  0.276816175 val =  0.906015\n",
      "532 Epoch: 0008 cost =  0.244001816 val =  0.906015\n",
      "532 Epoch: 0009 cost =  0.223395592 val =  0.909774\n",
      "532 Epoch: 0010 cost =  0.204934289 val =  0.921053\n",
      "532 Epoch: 0011 cost =  0.189242238 val =  0.926692\n",
      "532 Epoch: 0012 cost =  0.173931385 val =  0.930451\n",
      "532 Epoch: 0013 cost =  0.165288117 val =  0.932331\n",
      "532 Epoch: 0014 cost =  0.158405693 val =  0.932331\n",
      "532 Epoch: 0015 cost =  0.151738906 val =  0.937970\n",
      "532 Epoch: 0016 cost =  0.147534303 val =  0.939850\n",
      "532 Epoch: 0017 cost =  0.145097108 val =  0.941729\n",
      "532 Epoch: 0018 cost =  0.143272567 val =  0.939850\n",
      "532 Epoch: 0019 cost =  0.141328336 val =  0.939850\n",
      "532 Epoch: 0020 cost =  0.140013050 val =  0.943609\n",
      "532 Epoch: 0021 cost =  0.139203431 val =  0.943609\n",
      "532 Epoch: 0022 cost =  0.136673529 val =  0.945489\n",
      "532 Epoch: 0023 cost =  0.135562837 val =  0.945489\n",
      "532 Epoch: 0024 cost =  0.134657768 val =  0.949248\n",
      "532 Epoch: 0025 cost =  0.134129699 val =  0.947368\n",
      "532 Epoch: 0026 cost =  0.131178061 val =  0.947368\n",
      "532 Epoch: 0027 cost =  0.130104292 val =  0.945489\n",
      "532 Epoch: 0028 cost =  0.128867222 val =  0.945489\n",
      "532 Epoch: 0029 cost =  0.127684433 val =  0.943609\n",
      "532 Epoch: 0030 cost =  0.126975066 val =  0.943609\n",
      "532 Epoch: 0031 cost =  0.126010627 val =  0.943609\n",
      "532 Epoch: 0032 cost =  0.125013071 val =  0.943609\n",
      "532 Epoch: 0033 cost =  0.124207640 val =  0.941729\n",
      "532 Epoch: 0034 cost =  0.123146853 val =  0.943609\n",
      "532 Epoch: 0035 cost =  0.121697093 val =  0.941729\n",
      "532 Epoch: 0036 cost =  0.120310844 val =  0.941729\n",
      "532 Epoch: 0037 cost =  0.119928162 val =  0.941729\n",
      "532 Epoch: 0038 cost =  0.118795767 val =  0.941729\n",
      "532 Epoch: 0039 cost =  0.117779193 val =  0.941729\n",
      "532 Epoch: 0040 cost =  0.116981648 val =  0.941729\n",
      "532 Epoch: 0041 cost =  0.116218975 val =  0.939850\n",
      "532 Epoch: 0042 cost =  0.115472553 val =  0.939850\n",
      "532 Epoch: 0043 cost =  0.114580262 val =  0.936090\n",
      "532 Epoch: 0044 cost =  0.114024108 val =  0.939850\n",
      "532 Epoch: 0045 cost =  0.113274425 val =  0.939850\n",
      "532 Epoch: 0046 cost =  0.112575974 val =  0.937970\n",
      "532 Epoch: 0047 cost =  0.111738523 val =  0.939850\n",
      "532 Epoch: 0048 cost =  0.111040375 val =  0.939850\n",
      "532 Epoch: 0049 cost =  0.110312443 val =  0.941729\n",
      "532 Epoch: 0050 cost =  0.109617098 val =  0.941729\n",
      "532 Epoch: 0051 cost =  0.108920713 val =  0.937970\n",
      "532 Epoch: 0052 cost =  0.108235957 val =  0.941729\n",
      "532 Epoch: 0053 cost =  0.107560988 val =  0.941729\n",
      "532 Epoch: 0054 cost =  0.106906644 val =  0.941729\n",
      "532 Epoch: 0055 cost =  0.106307829 val =  0.937970\n",
      "532 Epoch: 0056 cost =  0.105478135 val =  0.939850\n",
      "532 Epoch: 0057 cost =  0.105144072 val =  0.939850\n",
      "532 Epoch: 0058 cost =  0.104410192 val =  0.939850\n",
      "532 Epoch: 0059 cost =  0.103447442 val =  0.939850\n",
      "532 Epoch: 0060 cost =  0.103289687 val =  0.939850\n",
      "532 Epoch: 0061 cost =  0.102438361 val =  0.939850\n",
      "532 Epoch: 0062 cost =  0.102220183 val =  0.939850\n",
      "532 Epoch: 0063 cost =  0.101412787 val =  0.937970\n",
      "532 Epoch: 0064 cost =  0.100849484 val =  0.937970\n",
      "532 Epoch: 0065 cost =  0.099937149 val =  0.937970\n",
      "532 Epoch: 0066 cost =  0.099752758 val =  0.939850\n",
      "532 Epoch: 0067 cost =  0.099130929 val =  0.939850\n",
      "532 Epoch: 0068 cost =  0.098569544 val =  0.939850\n",
      "532 Epoch: 0069 cost =  0.098014931 val =  0.939850\n",
      "532 Epoch: 0070 cost =  0.097506335 val =  0.937970\n",
      "532 Epoch: 0071 cost =  0.096918079 val =  0.939850\n",
      "532 Epoch: 0072 cost =  0.096180221 val =  0.937970\n",
      "532 Epoch: 0073 cost =  0.095607247 val =  0.937970\n",
      "532 Epoch: 0074 cost =  0.095103301 val =  0.939850\n",
      "532 Epoch: 0075 cost =  0.094610662 val =  0.939850\n",
      "532 Epoch: 0076 cost =  0.094083863 val =  0.939850\n",
      "532 Epoch: 0077 cost =  0.093642488 val =  0.939850\n",
      "532 Epoch: 0078 cost =  0.093067119 val =  0.939850\n",
      "532 Epoch: 0079 cost =  0.092693554 val =  0.939850\n",
      "532 Epoch: 0080 cost =  0.092134733 val =  0.939850\n",
      "532 Epoch: 0081 cost =  0.091738349 val =  0.941729\n",
      "532 Epoch: 0082 cost =  0.091215611 val =  0.943609\n",
      "532 Epoch: 0083 cost =  0.090651151 val =  0.943609\n",
      "532 Epoch: 0084 cost =  0.090206464 val =  0.943609\n",
      "532 Epoch: 0085 cost =  0.089656337 val =  0.943609\n",
      "532 Epoch: 0086 cost =  0.089222025 val =  0.943609\n",
      "532 Epoch: 0087 cost =  0.088782347 val =  0.943609\n",
      "532 Epoch: 0088 cost =  0.088328581 val =  0.943609\n",
      "532 Epoch: 0089 cost =  0.087922844 val =  0.943609\n",
      "532 Epoch: 0090 cost =  0.087314016 val =  0.943609\n",
      "532 Epoch: 0091 cost =  0.086891359 val =  0.941729\n",
      "532 Epoch: 0092 cost =  0.086452382 val =  0.943609\n",
      "532 Epoch: 0093 cost =  0.086084927 val =  0.941729\n",
      "532 Epoch: 0094 cost =  0.085638916 val =  0.943609\n",
      "532 Epoch: 0095 cost =  0.085207795 val =  0.941729\n",
      "532 Epoch: 0096 cost =  0.084760637 val =  0.941729\n",
      "532 Epoch: 0097 cost =  0.084315321 val =  0.941729\n",
      "532 Epoch: 0098 cost =  0.085181552 val =  0.945489\n",
      "532 Epoch: 0099 cost =  0.093507418 val =  0.937970\n",
      "532 Epoch: 0100 cost =  0.091585470 val =  0.947368\n",
      "532 Epoch: 0101 cost =  0.084893548 val =  0.945489\n",
      "532 Epoch: 0102 cost =  0.083918030 val =  0.945489\n",
      "532 Epoch: 0103 cost =  0.083086517 val =  0.943609\n",
      "532 Epoch: 0104 cost =  0.082446482 val =  0.945489\n",
      "532 Epoch: 0105 cost =  0.081694310 val =  0.945489\n",
      "532 Epoch: 0106 cost =  0.081583652 val =  0.945489\n",
      "532 Epoch: 0107 cost =  0.081318444 val =  0.945489\n",
      "532 Epoch: 0108 cost =  0.080853491 val =  0.945489\n",
      "532 Epoch: 0109 cost =  0.080490557 val =  0.945489\n",
      "532 Epoch: 0110 cost =  0.080100964 val =  0.945489\n",
      "532 Epoch: 0111 cost =  0.079807695 val =  0.945489\n",
      "532 Epoch: 0112 cost =  0.079540721 val =  0.945489\n",
      "532 Epoch: 0113 cost =  0.079267179 val =  0.945489\n",
      "532 Epoch: 0114 cost =  0.078935733 val =  0.945489\n",
      "532 Epoch: 0115 cost =  0.078590901 val =  0.945489\n",
      "532 Epoch: 0116 cost =  0.078227878 val =  0.945489\n",
      "532 Epoch: 0117 cost =  0.078008936 val =  0.945489\n",
      "532 Epoch: 0118 cost =  0.077670114 val =  0.945489\n",
      "532 Epoch: 0119 cost =  0.077372532 val =  0.945489\n",
      "532 Epoch: 0120 cost =  0.077055997 val =  0.945489\n",
      "532 Epoch: 0121 cost =  0.076757018 val =  0.945489\n",
      "532 Epoch: 0122 cost =  0.076430078 val =  0.945489\n",
      "532 Epoch: 0123 cost =  0.076146368 val =  0.945489\n",
      "532 Epoch: 0124 cost =  0.075820384 val =  0.945489\n",
      "532 Epoch: 0125 cost =  0.075562375 val =  0.945489\n",
      "532 Epoch: 0126 cost =  0.075243156 val =  0.945489\n",
      "532 Epoch: 0127 cost =  0.074997534 val =  0.945489\n",
      "532 Epoch: 0128 cost =  0.074680027 val =  0.945489\n",
      "532 Epoch: 0129 cost =  0.074410988 val =  0.945489\n",
      "532 Epoch: 0130 cost =  0.074233490 val =  0.945489\n",
      "532 Epoch: 0131 cost =  0.073928812 val =  0.945489\n",
      "532 Epoch: 0132 cost =  0.073612675 val =  0.943609\n",
      "532 Epoch: 0133 cost =  0.073382712 val =  0.943609\n",
      "532 Epoch: 0134 cost =  0.073154114 val =  0.943609\n",
      "532 Epoch: 0135 cost =  0.072855575 val =  0.943609\n",
      "532 Epoch: 0136 cost =  0.072651845 val =  0.941729\n",
      "532 Epoch: 0137 cost =  0.072506543 val =  0.941729\n",
      "532 Epoch: 0138 cost =  0.072008647 val =  0.941729\n",
      "532 Epoch: 0139 cost =  0.071421450 val =  0.941729\n",
      "532 Epoch: 0140 cost =  0.071088124 val =  0.937970\n",
      "532 Epoch: 0141 cost =  0.072397374 val =  0.939850\n",
      "532 Epoch: 0142 cost =  0.070775254 val =  0.941729\n",
      "532 Epoch: 0143 cost =  0.070681466 val =  0.941729\n",
      "532 Epoch: 0144 cost =  0.070112463 val =  0.941729\n",
      "532 Epoch: 0145 cost =  0.070181688 val =  0.943609\n",
      "532 Epoch: 0146 cost =  0.069785305 val =  0.941729\n",
      "532 Epoch: 0147 cost =  0.068572594 val =  0.943609\n",
      "532 Epoch: 0148 cost =  0.068297019 val =  0.943609\n",
      "532 Epoch: 0149 cost =  0.067767675 val =  0.943609\n",
      "532 Epoch: 0150 cost =  0.067218764 val =  0.943609\n",
      "532 Epoch: 0151 cost =  0.066870125 val =  0.943609\n",
      "532 Epoch: 0152 cost =  0.066457991 val =  0.943609\n",
      "532 Epoch: 0153 cost =  0.066034951 val =  0.943609\n",
      "532 Epoch: 0154 cost =  0.065612535 val =  0.943609\n",
      "532 Epoch: 0155 cost =  0.065368687 val =  0.943609\n",
      "532 Epoch: 0156 cost =  0.064936043 val =  0.943609\n",
      "532 Epoch: 0157 cost =  0.064454568 val =  0.943609\n",
      "532 Epoch: 0158 cost =  0.064816090 val =  0.943609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 Epoch: 0159 cost =  0.064080153 val =  0.939850\n",
      "532 Epoch: 0160 cost =  0.063961403 val =  0.939850\n",
      "532 Epoch: 0161 cost =  0.063349965 val =  0.937970\n",
      "532 Epoch: 0162 cost =  0.063071231 val =  0.941729\n",
      "532 Epoch: 0163 cost =  0.062458390 val =  0.941729\n",
      "532 Epoch: 0164 cost =  0.061942070 val =  0.943609\n",
      "532 Epoch: 0165 cost =  0.062567283 val =  0.939850\n",
      "532 Epoch: 0166 cost =  0.061236206 val =  0.941729\n",
      "532 Epoch: 0167 cost =  0.060791749 val =  0.941729\n",
      "532 Epoch: 0168 cost =  0.060606425 val =  0.939850\n",
      "532 Epoch: 0169 cost =  0.060271733 val =  0.939850\n",
      "532 Epoch: 0170 cost =  0.060215775 val =  0.939850\n",
      "532 Epoch: 0171 cost =  0.059874867 val =  0.939850\n",
      "532 Epoch: 0172 cost =  0.059756864 val =  0.939850\n",
      "532 Epoch: 0173 cost =  0.059488328 val =  0.939850\n",
      "532 Epoch: 0174 cost =  0.059419110 val =  0.939850\n",
      "532 Epoch: 0175 cost =  0.059045447 val =  0.939850\n",
      "532 Epoch: 0176 cost =  0.059096778 val =  0.939850\n",
      "532 Epoch: 0177 cost =  0.058703341 val =  0.939850\n",
      "532 Epoch: 0178 cost =  0.058632277 val =  0.939850\n",
      "532 Epoch: 0179 cost =  0.058290402 val =  0.937970\n",
      "532 Epoch: 0180 cost =  0.058217818 val =  0.939850\n",
      "532 Epoch: 0181 cost =  0.057965863 val =  0.937970\n",
      "532 Epoch: 0182 cost =  0.057764769 val =  0.937970\n",
      "532 Epoch: 0183 cost =  0.057619434 val =  0.937970\n",
      "532 Epoch: 0184 cost =  0.057286439 val =  0.937970\n",
      "532 Epoch: 0185 cost =  0.057212899 val =  0.937970\n",
      "532 Epoch: 0186 cost =  0.056887307 val =  0.937970\n",
      "532 Epoch: 0187 cost =  0.056922241 val =  0.937970\n",
      "532 Epoch: 0188 cost =  0.056628446 val =  0.937970\n",
      "532 Epoch: 0189 cost =  0.056367616 val =  0.937970\n",
      "532 Epoch: 0190 cost =  0.056232769 val =  0.937970\n",
      "532 Epoch: 0191 cost =  0.056131852 val =  0.936090\n",
      "532 Epoch: 0192 cost =  0.055876591 val =  0.936090\n",
      "532 Epoch: 0193 cost =  0.055724596 val =  0.936090\n",
      "532 Epoch: 0194 cost =  0.055699258 val =  0.937970\n",
      "532 Epoch: 0195 cost =  0.055477098 val =  0.936090\n",
      "532 Epoch: 0196 cost =  0.055379078 val =  0.936090\n",
      "532 Epoch: 0197 cost =  0.055087799 val =  0.936090\n",
      "532 Epoch: 0198 cost =  0.055095090 val =  0.936090\n",
      "532 Epoch: 0199 cost =  0.054798052 val =  0.936090\n",
      "532 Epoch: 0200 cost =  0.054846709 val =  0.936090\n",
      "532 Epoch: 0201 cost =  0.054537333 val =  0.936090\n",
      "532 Epoch: 0202 cost =  0.054611791 val =  0.936090\n",
      "532 Epoch: 0203 cost =  0.054312220 val =  0.936090\n",
      "532 Epoch: 0204 cost =  0.054433021 val =  0.937970\n",
      "532 Epoch: 0205 cost =  0.054182993 val =  0.936090\n",
      "532 Epoch: 0206 cost =  0.054002082 val =  0.936090\n",
      "532 Epoch: 0207 cost =  0.053948951 val =  0.936090\n",
      "532 Epoch: 0208 cost =  0.053931813 val =  0.936090\n",
      "532 Epoch: 0209 cost =  0.053757785 val =  0.936090\n",
      "532 Epoch: 0210 cost =  0.053772193 val =  0.936090\n",
      "532 Epoch: 0211 cost =  0.053400398 val =  0.936090\n",
      "532 Epoch: 0212 cost =  0.053455213 val =  0.936090\n",
      "532 Epoch: 0213 cost =  0.053252481 val =  0.936090\n",
      "532 Epoch: 0214 cost =  0.053057538 val =  0.936090\n",
      "532 Epoch: 0215 cost =  0.052986112 val =  0.936090\n",
      "532 Epoch: 0216 cost =  0.053020244 val =  0.937970\n",
      "532 Epoch: 0217 cost =  0.052812823 val =  0.937970\n",
      "532 Epoch: 0218 cost =  0.052574940 val =  0.936090\n",
      "532 Epoch: 0219 cost =  0.052505567 val =  0.936090\n",
      "532 Epoch: 0220 cost =  0.052547522 val =  0.937970\n",
      "532 Epoch: 0221 cost =  0.052404775 val =  0.937970\n",
      "532 Epoch: 0222 cost =  0.052164015 val =  0.936090\n",
      "532 Epoch: 0223 cost =  0.052087357 val =  0.936090\n",
      "532 Epoch: 0224 cost =  0.052091896 val =  0.937970\n",
      "532 Epoch: 0225 cost =  0.051930873 val =  0.937970\n",
      "532 Epoch: 0226 cost =  0.051734261 val =  0.936090\n",
      "532 Epoch: 0227 cost =  0.051676377 val =  0.936090\n",
      "532 Epoch: 0228 cost =  0.051660809 val =  0.937970\n",
      "532 Epoch: 0229 cost =  0.051439979 val =  0.936090\n",
      "532 Epoch: 0230 cost =  0.051437604 val =  0.937970\n",
      "532 Epoch: 0231 cost =  0.051254313 val =  0.936090\n",
      "532 Epoch: 0232 cost =  0.051159801 val =  0.936090\n",
      "532 Epoch: 0233 cost =  0.051178915 val =  0.937970\n",
      "532 Epoch: 0234 cost =  0.051074533 val =  0.937970\n",
      "532 Epoch: 0235 cost =  0.050948157 val =  0.937970\n",
      "532 Epoch: 0236 cost =  0.050790354 val =  0.937970\n",
      "532 Epoch: 0237 cost =  0.050667778 val =  0.936090\n",
      "532 Epoch: 0238 cost =  0.050693386 val =  0.937970\n",
      "532 Epoch: 0239 cost =  0.050589694 val =  0.937970\n",
      "532 Epoch: 0240 cost =  0.050546858 val =  0.936090\n",
      "532 Epoch: 0241 cost =  0.050505790 val =  0.937970\n",
      "532 Epoch: 0242 cost =  0.050356197 val =  0.937970\n",
      "532 Epoch: 0243 cost =  0.050274129 val =  0.937970\n",
      "532 Epoch: 0244 cost =  0.050178332 val =  0.936090\n",
      "532 Epoch: 0245 cost =  0.050005403 val =  0.937970\n",
      "532 Epoch: 0246 cost =  0.049931638 val =  0.936090\n",
      "532 Epoch: 0247 cost =  0.049918534 val =  0.937970\n",
      "532 Epoch: 0248 cost =  0.049958170 val =  0.937970\n",
      "532 Epoch: 0249 cost =  0.049912232 val =  0.939850\n",
      "532 Epoch: 0250 cost =  0.049929857 val =  0.937970\n",
      "532 Epoch: 0251 cost =  0.050164465 val =  0.937970\n",
      "532 Epoch: 0252 cost =  0.050335020 val =  0.945489\n",
      "532 Epoch: 0253 cost =  0.050342840 val =  0.943609\n",
      "532 Epoch: 0254 cost =  0.052029831 val =  0.947368\n",
      "532 Epoch: 0255 cost =  0.050364674 val =  0.939850\n",
      "532 Epoch: 0256 cost =  0.049536065 val =  0.936090\n",
      "532 Epoch: 0257 cost =  0.049147174 val =  0.936090\n",
      "532 Epoch: 0258 cost =  0.048877949 val =  0.936090\n",
      "532 Epoch: 0259 cost =  0.048825341 val =  0.936090\n",
      "532 Epoch: 0260 cost =  0.048911803 val =  0.936090\n",
      "532 Epoch: 0261 cost =  0.048907540 val =  0.936090\n",
      "532 Epoch: 0262 cost =  0.048747094 val =  0.936090\n",
      "532 Epoch: 0263 cost =  0.048608965 val =  0.936090\n",
      "532 Epoch: 0264 cost =  0.048382392 val =  0.936090\n",
      "532 Epoch: 0265 cost =  0.048401253 val =  0.936090\n",
      "532 Epoch: 0266 cost =  0.048605988 val =  0.936090\n",
      "532 Epoch: 0267 cost =  0.048427247 val =  0.934211\n",
      "532 Epoch: 0268 cost =  0.048303168 val =  0.934211\n",
      "532 Epoch: 0269 cost =  0.048104926 val =  0.934211\n",
      "532 Epoch: 0270 cost =  0.048246628 val =  0.936090\n",
      "532 Epoch: 0271 cost =  0.048085973 val =  0.936090\n",
      "532 Epoch: 0272 cost =  0.048014804 val =  0.936090\n",
      "532 Epoch: 0273 cost =  0.047868782 val =  0.936090\n",
      "532 Epoch: 0274 cost =  0.047814351 val =  0.936090\n",
      "532 Epoch: 0275 cost =  0.047727329 val =  0.936090\n",
      "532 Epoch: 0276 cost =  0.047658085 val =  0.936090\n",
      "532 Epoch: 0277 cost =  0.047647828 val =  0.934211\n",
      "532 Epoch: 0278 cost =  0.047671857 val =  0.936090\n",
      "532 Epoch: 0279 cost =  0.047657587 val =  0.934211\n",
      "532 Epoch: 0280 cost =  0.047583133 val =  0.934211\n",
      "532 Epoch: 0281 cost =  0.048547297 val =  0.932331\n",
      "532 Epoch: 0282 cost =  0.047519532 val =  0.934211\n",
      "532 Epoch: 0283 cost =  0.047267996 val =  0.934211\n",
      "532 Epoch: 0284 cost =  0.047146459 val =  0.937970\n",
      "532 Epoch: 0285 cost =  0.047059552 val =  0.937970\n",
      "532 Epoch: 0286 cost =  0.047221951 val =  0.937970\n",
      "532 Epoch: 0287 cost =  0.047696932 val =  0.934211\n",
      "532 Epoch: 0288 cost =  0.047100112 val =  0.936090\n",
      "532 Epoch: 0289 cost =  0.046930082 val =  0.936090\n",
      "532 Epoch: 0290 cost =  0.046850989 val =  0.936090\n",
      "532 Epoch: 0291 cost =  0.046733642 val =  0.937970\n",
      "532 Epoch: 0292 cost =  0.046754433 val =  0.937970\n",
      "532 Epoch: 0293 cost =  0.046649403 val =  0.937970\n",
      "532 Epoch: 0294 cost =  0.046753913 val =  0.937970\n",
      "532 Epoch: 0295 cost =  0.046974729 val =  0.937970\n",
      "532 Epoch: 0296 cost =  0.046606789 val =  0.937970\n",
      "532 Epoch: 0297 cost =  0.046762940 val =  0.937970\n",
      "532 Epoch: 0298 cost =  0.046386096 val =  0.937970\n",
      "532 Epoch: 0299 cost =  0.046341649 val =  0.937970\n",
      "532 Epoch: 0300 cost =  0.046276859 val =  0.937970\n",
      "532 Epoch: 0301 cost =  0.046250969 val =  0.937970\n",
      "532 Epoch: 0302 cost =  0.046540168 val =  0.939850\n",
      "532 Epoch: 0303 cost =  0.049033692 val =  0.937970\n",
      "532 Epoch: 0304 cost =  0.047037488 val =  0.937970\n",
      "532 Epoch: 0305 cost =  0.046624244 val =  0.937970\n",
      "532 Epoch: 0306 cost =  0.046294649 val =  0.937970\n",
      "532 Epoch: 0307 cost =  0.046260160 val =  0.937970\n",
      "532 Epoch: 0308 cost =  0.046191274 val =  0.937970\n",
      "532 Epoch: 0309 cost =  0.046129158 val =  0.937970\n",
      "532 Epoch: 0310 cost =  0.045944889 val =  0.937970\n",
      "532 Epoch: 0311 cost =  0.045876909 val =  0.937970\n",
      "532 Epoch: 0312 cost =  0.045839220 val =  0.937970\n",
      "532 Epoch: 0313 cost =  0.045864115 val =  0.937970\n",
      "532 Epoch: 0314 cost =  0.046049135 val =  0.937970\n",
      "532 Epoch: 0315 cost =  0.045965718 val =  0.937970\n",
      "532 Epoch: 0316 cost =  0.045684036 val =  0.937970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 Epoch: 0317 cost =  0.045649254 val =  0.937970\n",
      "532 Epoch: 0318 cost =  0.045659666 val =  0.937970\n",
      "532 Epoch: 0319 cost =  0.045557385 val =  0.937970\n",
      "532 Epoch: 0320 cost =  0.045785618 val =  0.937970\n",
      "532 Epoch: 0321 cost =  0.046112572 val =  0.936090\n",
      "532 Epoch: 0322 cost =  0.045938043 val =  0.937970\n",
      "532 Epoch: 0323 cost =  0.045768943 val =  0.937970\n",
      "532 Epoch: 0324 cost =  0.045696058 val =  0.937970\n",
      "532 Epoch: 0325 cost =  0.045406555 val =  0.937970\n",
      "532 Epoch: 0326 cost =  0.045495177 val =  0.937970\n",
      "532 Epoch: 0327 cost =  0.045691138 val =  0.937970\n",
      "532 Epoch: 0328 cost =  0.047844858 val =  0.939850\n",
      "532 Epoch: 0329 cost =  0.046225785 val =  0.939850\n",
      "532 Epoch: 0330 cost =  0.045687434 val =  0.937970\n",
      "532 Epoch: 0331 cost =  0.045645210 val =  0.939850\n",
      "532 Epoch: 0332 cost =  0.045661178 val =  0.937970\n",
      "532 Epoch: 0333 cost =  0.046749361 val =  0.941729\n",
      "532 Epoch: 0334 cost =  0.045560880 val =  0.939850\n",
      "532 Epoch: 0335 cost =  0.045379551 val =  0.937970\n",
      "532 Epoch: 0336 cost =  0.045431467 val =  0.937970\n",
      "532 Epoch: 0337 cost =  0.046234263 val =  0.936090\n",
      "532 Epoch: 0338 cost =  0.045412556 val =  0.937970\n",
      "532 Epoch: 0339 cost =  0.045385588 val =  0.939850\n",
      "532 Epoch: 0340 cost =  0.045289205 val =  0.937970\n",
      "532 Epoch: 0341 cost =  0.045242087 val =  0.937970\n",
      "532 Epoch: 0342 cost =  0.045201558 val =  0.937970\n",
      "532 Epoch: 0343 cost =  0.045209125 val =  0.937970\n",
      "532 Epoch: 0344 cost =  0.044890826 val =  0.937970\n",
      "532 Epoch: 0345 cost =  0.045064874 val =  0.939850\n",
      "532 Epoch: 0346 cost =  0.045273932 val =  0.939850\n",
      "532 Epoch: 0347 cost =  0.045238466 val =  0.937970\n",
      "532 Epoch: 0348 cost =  0.046731169 val =  0.937970\n",
      "532 Epoch: 0349 cost =  0.045992045 val =  0.939850\n",
      "532 Epoch: 0350 cost =  0.045074150 val =  0.937970\n",
      "532 Epoch: 0351 cost =  0.045128895 val =  0.937970\n",
      "532 Epoch: 0352 cost =  0.045035546 val =  0.937970\n",
      "532 Epoch: 0353 cost =  0.044962537 val =  0.937970\n",
      "532 Epoch: 0354 cost =  0.044890535 val =  0.937970\n",
      "532 Epoch: 0355 cost =  0.044866680 val =  0.937970\n",
      "532 Epoch: 0356 cost =  0.044842967 val =  0.937970\n",
      "532 Epoch: 0357 cost =  0.044645663 val =  0.937970\n",
      "532 Epoch: 0358 cost =  0.044780528 val =  0.939850\n",
      "532 Epoch: 0359 cost =  0.044649854 val =  0.939850\n",
      "532 Epoch: 0360 cost =  0.044747172 val =  0.937970\n",
      "532 Epoch: 0361 cost =  0.044693034 val =  0.939850\n",
      "532 Epoch: 0362 cost =  0.044641425 val =  0.939850\n",
      "532 Epoch: 0363 cost =  0.044762113 val =  0.941729\n",
      "532 Epoch: 0364 cost =  0.044894504 val =  0.939850\n",
      "532 Epoch: 0365 cost =  0.044598764 val =  0.939850\n",
      "532 Epoch: 0366 cost =  0.044522076 val =  0.939850\n",
      "532 Epoch: 0367 cost =  0.044459332 val =  0.941729\n",
      "532 Epoch: 0368 cost =  0.044392289 val =  0.941729\n",
      "532 Epoch: 0369 cost =  0.044583506 val =  0.939850\n",
      "532 Epoch: 0370 cost =  0.044671187 val =  0.939850\n",
      "532 Epoch: 0371 cost =  0.045748892 val =  0.941729\n",
      "532 Epoch: 0372 cost =  0.044642170 val =  0.943609\n",
      "532 Epoch: 0373 cost =  0.044574800 val =  0.939850\n",
      "532 Epoch: 0374 cost =  0.044474024 val =  0.941729\n",
      "532 Epoch: 0375 cost =  0.044378443 val =  0.941729\n",
      "532 Epoch: 0376 cost =  0.045850964 val =  0.941729\n",
      "532 Epoch: 0377 cost =  0.044881659 val =  0.939850\n",
      "532 Epoch: 0378 cost =  0.044640461 val =  0.941729\n",
      "532 Epoch: 0379 cost =  0.044317792 val =  0.941729\n",
      "532 Epoch: 0380 cost =  0.044272617 val =  0.939850\n",
      "532 Epoch: 0381 cost =  0.044481988 val =  0.941729\n",
      "532 Epoch: 0382 cost =  0.044292923 val =  0.941729\n",
      "532 Epoch: 0383 cost =  0.044178620 val =  0.941729\n",
      "532 Epoch: 0384 cost =  0.047620493 val =  0.941729\n",
      "532 Epoch: 0385 cost =  0.044837421 val =  0.941729\n",
      "532 Epoch: 0386 cost =  0.044424912 val =  0.939850\n",
      "532 Epoch: 0387 cost =  0.044301612 val =  0.939850\n",
      "532 Epoch: 0388 cost =  0.044208670 val =  0.939850\n",
      "532 Epoch: 0389 cost =  0.044094661 val =  0.939850\n",
      "532 Epoch: 0390 cost =  0.044096265 val =  0.941729\n",
      "532 Epoch: 0391 cost =  0.043977619 val =  0.939850\n",
      "532 Epoch: 0392 cost =  0.044077815 val =  0.941729\n",
      "532 Epoch: 0393 cost =  0.044089326 val =  0.941729\n",
      "532 Epoch: 0394 cost =  0.043989700 val =  0.941729\n",
      "532 Epoch: 0395 cost =  0.044051623 val =  0.943609\n",
      "532 Epoch: 0396 cost =  0.043932028 val =  0.941729\n",
      "532 Epoch: 0397 cost =  0.043890667 val =  0.943609\n",
      "532 Epoch: 0398 cost =  0.043989180 val =  0.939850\n",
      "532 Epoch: 0399 cost =  0.044176292 val =  0.941729\n",
      "532 Epoch: 0400 cost =  0.043961940 val =  0.941729\n",
      "532 Epoch: 0401 cost =  0.043861726 val =  0.939850\n",
      "532 Epoch: 0402 cost =  0.043903702 val =  0.939850\n",
      "532 Epoch: 0403 cost =  0.043770881 val =  0.939850\n",
      "532 Epoch: 0404 cost =  0.045909964 val =  0.939850\n",
      "532 Epoch: 0405 cost =  0.044207505 val =  0.941729\n",
      "532 Epoch: 0406 cost =  0.044143732 val =  0.937970\n",
      "532 Epoch: 0407 cost =  0.044898256 val =  0.937970\n",
      "532 Epoch: 0408 cost =  0.044800479 val =  0.939850\n",
      "532 Epoch: 0409 cost =  0.043889444 val =  0.939850\n",
      "532 Epoch: 0410 cost =  0.043814465 val =  0.939850\n",
      "532 Epoch: 0411 cost =  0.043835596 val =  0.939850\n",
      "532 Epoch: 0412 cost =  0.043814554 val =  0.939850\n",
      "532 Epoch: 0413 cost =  0.043787607 val =  0.941729\n",
      "532 Epoch: 0414 cost =  0.046015543 val =  0.941729\n",
      "532 Epoch: 0415 cost =  0.044066281 val =  0.943609\n",
      "532 Epoch: 0416 cost =  0.043640613 val =  0.941729\n",
      "532 Epoch: 0417 cost =  0.043536976 val =  0.941729\n",
      "532 Epoch: 0418 cost =  0.043489246 val =  0.941729\n",
      "532 Epoch: 0419 cost =  0.043352583 val =  0.941729\n",
      "532 Epoch: 0420 cost =  0.043470979 val =  0.941729\n",
      "532 Epoch: 0421 cost =  0.043297203 val =  0.937970\n",
      "532 Epoch: 0422 cost =  0.043265475 val =  0.941729\n",
      "532 Epoch: 0423 cost =  0.043300862 val =  0.937970\n",
      "532 Epoch: 0424 cost =  0.043273483 val =  0.937970\n",
      "532 Epoch: 0425 cost =  0.043149365 val =  0.937970\n",
      "532 Epoch: 0426 cost =  0.043122647 val =  0.939850\n",
      "532 Epoch: 0427 cost =  0.043046490 val =  0.937970\n",
      "532 Epoch: 0428 cost =  0.043072368 val =  0.939850\n",
      "532 Epoch: 0429 cost =  0.043086787 val =  0.937970\n",
      "532 Epoch: 0430 cost =  0.043076994 val =  0.939850\n",
      "532 Epoch: 0431 cost =  0.042983612 val =  0.937970\n",
      "532 Epoch: 0432 cost =  0.043050517 val =  0.939850\n",
      "532 Epoch: 0433 cost =  0.042940783 val =  0.939850\n",
      "532 Epoch: 0434 cost =  0.042917428 val =  0.936090\n",
      "532 Epoch: 0435 cost =  0.043243679 val =  0.939850\n",
      "532 Epoch: 0436 cost =  0.042976314 val =  0.941729\n",
      "532 Epoch: 0437 cost =  0.042911899 val =  0.939850\n",
      "532 Epoch: 0438 cost =  0.042775822 val =  0.941729\n",
      "532 Epoch: 0439 cost =  0.042637170 val =  0.939850\n",
      "532 Epoch: 0440 cost =  0.042979736 val =  0.937970\n",
      "532 Epoch: 0441 cost =  0.042755224 val =  0.937970\n",
      "532 Epoch: 0442 cost =  0.042741777 val =  0.937970\n",
      "532 Epoch: 0443 cost =  0.042753384 val =  0.937970\n",
      "532 Epoch: 0444 cost =  0.042698015 val =  0.939850\n",
      "532 Epoch: 0445 cost =  0.042754341 val =  0.937970\n",
      "532 Epoch: 0446 cost =  0.042486477 val =  0.937970\n",
      "532 Epoch: 0447 cost =  0.042525993 val =  0.939850\n",
      "532 Epoch: 0448 cost =  0.042414780 val =  0.937970\n",
      "532 Epoch: 0449 cost =  0.042720397 val =  0.936090\n",
      "532 Epoch: 0450 cost =  0.042383273 val =  0.936090\n",
      "532 Epoch: 0451 cost =  0.042622200 val =  0.936090\n",
      "532 Epoch: 0452 cost =  0.042538974 val =  0.937970\n",
      "532 Epoch: 0453 cost =  0.042484941 val =  0.936090\n",
      "532 Epoch: 0454 cost =  0.042504213 val =  0.937970\n",
      "532 Epoch: 0455 cost =  0.042834619 val =  0.937970\n",
      "532 Epoch: 0456 cost =  0.042284209 val =  0.939850\n",
      "532 Epoch: 0457 cost =  0.043058771 val =  0.936090\n",
      "532 Epoch: 0458 cost =  0.043019990 val =  0.945489\n",
      "532 Epoch: 0459 cost =  0.054922233 val =  0.947368\n",
      "532 Epoch: 0460 cost =  0.051109703 val =  0.939850\n",
      "532 Epoch: 0461 cost =  0.042391112 val =  0.939850\n",
      "532 Epoch: 0462 cost =  0.041917797 val =  0.939850\n",
      "532 Epoch: 0463 cost =  0.042937270 val =  0.937970\n",
      "532 Epoch: 0464 cost =  0.041287012 val =  0.939850\n",
      "532 Epoch: 0465 cost =  0.041324732 val =  0.937970\n",
      "532 Epoch: 0466 cost =  0.041130566 val =  0.937970\n",
      "532 Epoch: 0467 cost =  0.040879559 val =  0.937970\n",
      "532 Epoch: 0468 cost =  0.040709904 val =  0.937970\n",
      "532 Epoch: 0469 cost =  0.040573261 val =  0.939850\n",
      "532 Epoch: 0470 cost =  0.040433197 val =  0.939850\n",
      "532 Epoch: 0471 cost =  0.040475853 val =  0.939850\n",
      "532 Epoch: 0472 cost =  0.040596296 val =  0.939850\n",
      "532 Epoch: 0473 cost =  0.040203741 val =  0.939850\n",
      "532 Epoch: 0474 cost =  0.040072711 val =  0.939850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 Epoch: 0475 cost =  0.039914744 val =  0.939850\n",
      "532 Epoch: 0476 cost =  0.039790855 val =  0.939850\n",
      "532 Epoch: 0477 cost =  0.039707438 val =  0.939850\n",
      "532 Epoch: 0478 cost =  0.039670995 val =  0.937970\n",
      "532 Epoch: 0479 cost =  0.039578686 val =  0.939850\n",
      "532 Epoch: 0480 cost =  0.039507473 val =  0.939850\n",
      "532 Epoch: 0481 cost =  0.039400848 val =  0.939850\n",
      "532 Epoch: 0482 cost =  0.039323527 val =  0.939850\n",
      "532 Epoch: 0483 cost =  0.039215850 val =  0.939850\n",
      "532 Epoch: 0484 cost =  0.039251028 val =  0.937970\n",
      "532 Epoch: 0485 cost =  0.039885842 val =  0.937970\n",
      "532 Epoch: 0486 cost =  0.039232262 val =  0.939850\n",
      "532 Epoch: 0487 cost =  0.039098310 val =  0.939850\n",
      "532 Epoch: 0488 cost =  0.038926876 val =  0.939850\n",
      "532 Epoch: 0489 cost =  0.038901535 val =  0.941729\n",
      "532 Epoch: 0490 cost =  0.038866691 val =  0.941729\n",
      "532 Epoch: 0491 cost =  0.038714202 val =  0.939850\n",
      "532 Epoch: 0492 cost =  0.038629582 val =  0.939850\n",
      "532 Epoch: 0493 cost =  0.038562008 val =  0.941729\n",
      "532 Epoch: 0494 cost =  0.038651760 val =  0.941729\n",
      "532 Epoch: 0495 cost =  0.038782658 val =  0.941729\n",
      "532 Epoch: 0496 cost =  0.038578959 val =  0.941729\n",
      "532 Epoch: 0497 cost =  0.038521467 val =  0.943609\n",
      "532 Epoch: 0498 cost =  0.038524490 val =  0.941729\n",
      "532 Epoch: 0499 cost =  0.038511852 val =  0.941729\n",
      "532 Epoch: 0500 cost =  0.038503638 val =  0.943609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../model/CNN/cnn_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "batch_size = 32\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "\n",
    "for epoch in range(training_epochs):#training epoch 500 / batch_size 128 --> acc 90%\n",
    "    avg_cost = 0\n",
    "    val_avg_cost =0\n",
    "    total_batch = int(y_train.shape[0] / batch_size)\n",
    "    for i in range(0, y_train.shape[0], batch_size):\n",
    "        feed_dict={X:X_train2[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "        avg_cost += c/total_batch \n",
    "    \n",
    "    y_pred = sess.run(logits, feed_dict={X:X_val2})\n",
    "    y_pred = sess.run(tf.argmax(y_pred,1))\n",
    "    y_true = y_val\n",
    "        \n",
    "    y_true = sess.run(tf.argmax(y_true,1))\n",
    "    print(len(y_pred),end=' ')\n",
    "    print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost), 'val = ','%f' %(accuracy_score(y_true, y_pred)) )\n",
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.947\n",
      "Accuracy:  0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       239\n",
      "           1       0.96      0.96      0.96       426\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       665\n",
      "   macro avg       0.94      0.94      0.94       665\n",
      "weighted avg       0.95      0.95      0.95       665\n",
      "\n",
      "[[223  16]\n",
      " [ 19 407]]\n"
     ]
    }
   ],
   "source": [
    "# Print Result\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

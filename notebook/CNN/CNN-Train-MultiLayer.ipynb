{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have been save the data, you don't have to preprocessing and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_path = '../../data/1m/*.wav'\n",
    "background_path = '../../data/background/*.wav'\n",
    "\n",
    "drone_files = glob.glob(drone_path)\n",
    "background_files = glob.glob(background_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 22050\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=22050):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088960,)\n",
      "(6032517,)\n"
     ]
    }
   ],
   "source": [
    "drone_raw = load(drone_files)\n",
    "background_raw = load(background_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=22050, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088960,)\n",
      "small end: (16, 9)\n",
      "(6032517,)\n",
      "small end: (16, 15)\n",
      "small end: (16, 7)\n",
      "(509, 16, 16) (509,)\n",
      "(1471, 16, 16) (1471,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_drone, y_drone = mfcc4(drone_raw, 1)\n",
    "mfcc_background, y_background = mfcc4(background_raw, 0)\n",
    "\n",
    "print(mfcc_drone.shape, y_drone.shape)\n",
    "print(mfcc_background.shape, y_background.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 16, 16) (1980,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_drone, mfcc_background), axis=0)\n",
    "#X = np.concatenate((mfcc_drone), axis=0)\n",
    "#X = X.reshape(-1, 16,16,1)\n",
    "y = np.hstack((y_drone, y_background))\n",
    "#y = np.hstack(y_drone)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 2)\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 16, 16) (396, 16, 16)\n",
      "(317, 16, 16) (317, 2)\n",
      "(1267, 2) (396, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save('../../data/X_train', X_train)\n",
    "np.save('../../data/X_test', X_test)\n",
    "np.save('../../data/X_val', X_val)\n",
    "np.save('../../data/y_val', y_val)\n",
    "np.save('../../data/y_train', y_train)\n",
    "np.save('../../data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load('../../data/X_train.npy')\n",
    "X_test = np.load('../../data/X_test.npy')\n",
    "X_val = np.load('../../data/X_val.npy')\n",
    "y_val = np.load('../../data/y_val.npy')\n",
    "y_train = np.load('../../data/y_train.npy')\n",
    "y_test = np.load('../../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - One convolutional layer /w no dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Experiment 3-2\n",
    "- learning rate 0.005\n",
    "- pooling stride 1x1\n",
    "- #filter 1\n",
    "- best result among every other settings\n",
    "- cost kept fluctuated during training. (0.8 -> 1.3) -- why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.0002  # 0.005\n",
    "training_epochs = 200 # 수정해봐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# dropout넣어야하나\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# 여기도\n",
    "flat = tf.reshape(pool2, [-1, 16*16*1])\n",
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_val2 = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model_path = '../../model/CNN/cnn_model'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 Epoch: 0001 cost =  4.502382989 val =  0.902208\n",
      "317 Epoch: 0002 cost =  0.485880493 val =  0.908517\n",
      "317 Epoch: 0003 cost =  0.301089113 val =  0.940063\n",
      "317 Epoch: 0004 cost =  0.192280141 val =  0.946372\n",
      "317 Epoch: 0005 cost =  0.142137232 val =  0.946372\n",
      "317 Epoch: 0006 cost =  0.121536774 val =  0.936909\n",
      "317 Epoch: 0007 cost =  0.099966530 val =  0.943218\n",
      "317 Epoch: 0008 cost =  0.084986897 val =  0.949527\n",
      "317 Epoch: 0009 cost =  0.082588585 val =  0.949527\n",
      "317 Epoch: 0010 cost =  0.069950305 val =  0.962145\n",
      "317 Epoch: 0011 cost =  0.059338561 val =  0.958991\n",
      "317 Epoch: 0012 cost =  0.049333148 val =  0.965300\n",
      "317 Epoch: 0013 cost =  0.042692683 val =  0.965300\n",
      "317 Epoch: 0014 cost =  0.045580400 val =  0.958991\n",
      "317 Epoch: 0015 cost =  0.053125886 val =  0.952681\n",
      "317 Epoch: 0016 cost =  0.054748150 val =  0.952681\n",
      "317 Epoch: 0017 cost =  0.050413150 val =  0.936909\n",
      "317 Epoch: 0018 cost =  0.055785802 val =  0.971609\n",
      "317 Epoch: 0019 cost =  0.051285459 val =  0.968454\n",
      "317 Epoch: 0020 cost =  0.058548007 val =  0.958991\n",
      "317 Epoch: 0021 cost =  0.033631793 val =  0.946372\n",
      "317 Epoch: 0022 cost =  0.038746781 val =  0.968454\n",
      "317 Epoch: 0023 cost =  0.035754002 val =  0.952681\n",
      "317 Epoch: 0024 cost =  0.036211515 val =  0.968454\n",
      "317 Epoch: 0025 cost =  0.034984069 val =  0.965300\n",
      "317 Epoch: 0026 cost =  0.029537530 val =  0.968454\n",
      "317 Epoch: 0027 cost =  0.032425150 val =  0.940063\n",
      "317 Epoch: 0028 cost =  0.032149990 val =  0.974763\n",
      "317 Epoch: 0029 cost =  0.056718066 val =  0.952681\n",
      "317 Epoch: 0030 cost =  0.402274929 val =  0.943218\n",
      "317 Epoch: 0031 cost =  0.114642996 val =  0.974763\n",
      "317 Epoch: 0032 cost =  0.141596147 val =  0.977918\n",
      "317 Epoch: 0033 cost =  0.101982568 val =  0.977918\n",
      "317 Epoch: 0034 cost =  0.054131779 val =  0.974763\n",
      "317 Epoch: 0035 cost =  0.074081926 val =  0.974763\n",
      "317 Epoch: 0036 cost =  0.052494395 val =  0.952681\n",
      "317 Epoch: 0037 cost =  0.071126194 val =  0.936909\n",
      "317 Epoch: 0038 cost =  0.075777260 val =  0.958991\n",
      "317 Epoch: 0039 cost =  0.095907781 val =  0.958991\n",
      "317 Epoch: 0040 cost =  0.081478738 val =  0.952681\n",
      "317 Epoch: 0041 cost =  0.087227354 val =  0.902208\n",
      "317 Epoch: 0042 cost =  0.111353320 val =  0.917981\n",
      "317 Epoch: 0043 cost =  0.147789718 val =  0.955836\n",
      "317 Epoch: 0044 cost =  0.177104344 val =  0.958991\n",
      "317 Epoch: 0045 cost =  0.077163970 val =  0.971609\n",
      "317 Epoch: 0046 cost =  0.054733555 val =  0.971609\n",
      "317 Epoch: 0047 cost =  0.045456597 val =  0.974763\n",
      "317 Epoch: 0048 cost =  0.020632537 val =  0.971609\n",
      "317 Epoch: 0049 cost =  0.012178558 val =  0.971609\n",
      "317 Epoch: 0050 cost =  0.008951658 val =  0.971609\n",
      "317 Epoch: 0051 cost =  0.005793392 val =  0.971609\n",
      "317 Epoch: 0052 cost =  0.005658444 val =  0.971609\n",
      "317 Epoch: 0053 cost =  0.005005166 val =  0.971609\n",
      "317 Epoch: 0054 cost =  0.004192548 val =  0.971609\n",
      "317 Epoch: 0055 cost =  0.004606053 val =  0.971609\n",
      "317 Epoch: 0056 cost =  0.004307090 val =  0.971609\n",
      "317 Epoch: 0057 cost =  0.004013630 val =  0.971609\n",
      "317 Epoch: 0058 cost =  0.004034605 val =  0.974763\n",
      "317 Epoch: 0059 cost =  0.003948840 val =  0.974763\n",
      "317 Epoch: 0060 cost =  0.003716660 val =  0.974763\n",
      "317 Epoch: 0061 cost =  0.003613258 val =  0.974763\n",
      "317 Epoch: 0062 cost =  0.003314013 val =  0.974763\n",
      "317 Epoch: 0063 cost =  0.003592963 val =  0.974763\n",
      "317 Epoch: 0064 cost =  0.003496439 val =  0.974763\n",
      "317 Epoch: 0065 cost =  0.003120406 val =  0.974763\n",
      "317 Epoch: 0066 cost =  0.003183505 val =  0.974763\n",
      "317 Epoch: 0067 cost =  0.003157568 val =  0.974763\n",
      "317 Epoch: 0068 cost =  0.003125489 val =  0.974763\n",
      "317 Epoch: 0069 cost =  0.002829393 val =  0.974763\n",
      "317 Epoch: 0070 cost =  0.002930837 val =  0.974763\n",
      "317 Epoch: 0071 cost =  0.002739267 val =  0.971609\n",
      "317 Epoch: 0072 cost =  0.002636377 val =  0.974763\n",
      "317 Epoch: 0073 cost =  0.002730210 val =  0.971609\n",
      "317 Epoch: 0074 cost =  0.002419695 val =  0.971609\n",
      "317 Epoch: 0075 cost =  0.002419751 val =  0.971609\n",
      "317 Epoch: 0076 cost =  0.002472589 val =  0.974763\n",
      "317 Epoch: 0077 cost =  0.002204741 val =  0.974763\n",
      "317 Epoch: 0078 cost =  0.002109393 val =  0.974763\n",
      "317 Epoch: 0079 cost =  0.002202735 val =  0.974763\n",
      "317 Epoch: 0080 cost =  0.001987015 val =  0.974763\n",
      "317 Epoch: 0081 cost =  0.001913171 val =  0.974763\n",
      "317 Epoch: 0082 cost =  0.001910550 val =  0.974763\n",
      "317 Epoch: 0083 cost =  0.001883990 val =  0.974763\n",
      "317 Epoch: 0084 cost =  0.001648959 val =  0.974763\n",
      "317 Epoch: 0085 cost =  0.001626946 val =  0.974763\n",
      "317 Epoch: 0086 cost =  0.001603130 val =  0.974763\n",
      "317 Epoch: 0087 cost =  0.001541188 val =  0.974763\n",
      "317 Epoch: 0088 cost =  0.001503338 val =  0.974763\n",
      "317 Epoch: 0089 cost =  0.001369134 val =  0.974763\n",
      "317 Epoch: 0090 cost =  0.001262273 val =  0.977918\n",
      "317 Epoch: 0091 cost =  0.001230063 val =  0.974763\n",
      "317 Epoch: 0092 cost =  0.001136617 val =  0.977918\n",
      "317 Epoch: 0093 cost =  0.001066451 val =  0.981073\n",
      "317 Epoch: 0094 cost =  0.001004323 val =  0.981073\n",
      "317 Epoch: 0095 cost =  0.001004092 val =  0.981073\n",
      "317 Epoch: 0096 cost =  0.000937595 val =  0.984227\n",
      "317 Epoch: 0097 cost =  0.000941955 val =  0.984227\n",
      "317 Epoch: 0098 cost =  0.000909919 val =  0.981073\n",
      "317 Epoch: 0099 cost =  0.000910236 val =  0.981073\n",
      "317 Epoch: 0100 cost =  0.000875813 val =  0.981073\n",
      "317 Epoch: 0101 cost =  0.000826466 val =  0.984227\n",
      "317 Epoch: 0102 cost =  0.000818355 val =  0.984227\n",
      "317 Epoch: 0103 cost =  0.000762627 val =  0.984227\n",
      "317 Epoch: 0104 cost =  0.000714368 val =  0.981073\n",
      "317 Epoch: 0105 cost =  0.000704472 val =  0.981073\n",
      "317 Epoch: 0106 cost =  0.000649419 val =  0.981073\n",
      "317 Epoch: 0107 cost =  0.000597843 val =  0.981073\n",
      "317 Epoch: 0108 cost =  0.000558549 val =  0.981073\n",
      "317 Epoch: 0109 cost =  0.000521855 val =  0.981073\n",
      "317 Epoch: 0110 cost =  0.000469678 val =  0.977918\n",
      "317 Epoch: 0111 cost =  0.000383980 val =  0.981073\n",
      "317 Epoch: 0112 cost =  0.000302955 val =  0.981073\n",
      "317 Epoch: 0113 cost =  0.000207149 val =  0.981073\n",
      "317 Epoch: 0114 cost =  0.000178988 val =  0.981073\n",
      "317 Epoch: 0115 cost =  0.000167398 val =  0.981073\n",
      "317 Epoch: 0116 cost =  0.000163761 val =  0.981073\n",
      "317 Epoch: 0117 cost =  0.000160566 val =  0.981073\n",
      "317 Epoch: 0118 cost =  0.000157862 val =  0.981073\n",
      "317 Epoch: 0119 cost =  0.000153351 val =  0.981073\n",
      "317 Epoch: 0120 cost =  0.000149621 val =  0.981073\n",
      "317 Epoch: 0121 cost =  0.000146315 val =  0.981073\n",
      "317 Epoch: 0122 cost =  0.000143050 val =  0.981073\n",
      "317 Epoch: 0123 cost =  0.000140349 val =  0.981073\n",
      "317 Epoch: 0124 cost =  0.000137363 val =  0.981073\n",
      "317 Epoch: 0125 cost =  0.000134719 val =  0.981073\n",
      "317 Epoch: 0126 cost =  0.000132034 val =  0.981073\n",
      "317 Epoch: 0127 cost =  0.000130014 val =  0.981073\n",
      "317 Epoch: 0128 cost =  0.000126626 val =  0.981073\n",
      "317 Epoch: 0129 cost =  0.000124867 val =  0.981073\n",
      "317 Epoch: 0130 cost =  0.000122242 val =  0.981073\n",
      "317 Epoch: 0131 cost =  0.000120393 val =  0.981073\n",
      "317 Epoch: 0132 cost =  0.000118015 val =  0.981073\n",
      "317 Epoch: 0133 cost =  0.000115905 val =  0.981073\n",
      "317 Epoch: 0134 cost =  0.000113991 val =  0.981073\n",
      "317 Epoch: 0135 cost =  0.000111873 val =  0.981073\n",
      "317 Epoch: 0136 cost =  0.000110025 val =  0.981073\n",
      "317 Epoch: 0137 cost =  0.000108199 val =  0.981073\n",
      "317 Epoch: 0138 cost =  0.000106536 val =  0.981073\n",
      "317 Epoch: 0139 cost =  0.000104561 val =  0.981073\n",
      "317 Epoch: 0140 cost =  0.000103208 val =  0.981073\n",
      "317 Epoch: 0141 cost =  0.000101431 val =  0.981073\n",
      "317 Epoch: 0142 cost =  0.000099685 val =  0.981073\n",
      "317 Epoch: 0143 cost =  0.000098088 val =  0.981073\n",
      "317 Epoch: 0144 cost =  0.000096447 val =  0.981073\n",
      "317 Epoch: 0145 cost =  0.000095014 val =  0.981073\n",
      "317 Epoch: 0146 cost =  0.000093563 val =  0.981073\n",
      "317 Epoch: 0147 cost =  0.000091883 val =  0.981073\n",
      "317 Epoch: 0148 cost =  0.000090853 val =  0.981073\n",
      "317 Epoch: 0149 cost =  0.000089315 val =  0.981073\n",
      "317 Epoch: 0150 cost =  0.000087384 val =  0.981073\n",
      "317 Epoch: 0151 cost =  0.000086995 val =  0.981073\n",
      "317 Epoch: 0152 cost =  0.000084483 val =  0.981073\n",
      "317 Epoch: 0153 cost =  0.000083069 val =  0.981073\n",
      "317 Epoch: 0154 cost =  0.000081190 val =  0.981073\n",
      "317 Epoch: 0155 cost =  0.000079835 val =  0.981073\n",
      "317 Epoch: 0156 cost =  0.000077781 val =  0.981073\n",
      "317 Epoch: 0157 cost =  0.000077033 val =  0.981073\n",
      "317 Epoch: 0158 cost =  0.000075561 val =  0.981073\n",
      "317 Epoch: 0159 cost =  0.000074314 val =  0.981073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 Epoch: 0160 cost =  0.000072613 val =  0.981073\n",
      "317 Epoch: 0161 cost =  0.000071805 val =  0.981073\n",
      "317 Epoch: 0162 cost =  0.000070209 val =  0.981073\n",
      "317 Epoch: 0163 cost =  0.000069195 val =  0.981073\n",
      "317 Epoch: 0164 cost =  0.000067919 val =  0.981073\n",
      "317 Epoch: 0165 cost =  0.000066920 val =  0.981073\n",
      "317 Epoch: 0166 cost =  0.000066189 val =  0.981073\n",
      "317 Epoch: 0167 cost =  0.000064808 val =  0.981073\n",
      "317 Epoch: 0168 cost =  0.000063374 val =  0.981073\n",
      "317 Epoch: 0169 cost =  0.000062639 val =  0.981073\n",
      "317 Epoch: 0170 cost =  0.000061381 val =  0.981073\n",
      "317 Epoch: 0171 cost =  0.000060942 val =  0.981073\n",
      "317 Epoch: 0172 cost =  0.000059372 val =  0.981073\n",
      "317 Epoch: 0173 cost =  0.000058472 val =  0.981073\n",
      "317 Epoch: 0174 cost =  0.000057772 val =  0.981073\n",
      "317 Epoch: 0175 cost =  0.000056479 val =  0.981073\n",
      "317 Epoch: 0176 cost =  0.000055308 val =  0.981073\n",
      "317 Epoch: 0177 cost =  0.000055036 val =  0.981073\n",
      "317 Epoch: 0178 cost =  0.000053569 val =  0.981073\n",
      "317 Epoch: 0179 cost =  0.000052721 val =  0.981073\n",
      "317 Epoch: 0180 cost =  0.000052174 val =  0.981073\n",
      "317 Epoch: 0181 cost =  0.000050963 val =  0.981073\n",
      "317 Epoch: 0182 cost =  0.000049900 val =  0.981073\n",
      "317 Epoch: 0183 cost =  0.000049631 val =  0.981073\n",
      "317 Epoch: 0184 cost =  0.000048320 val =  0.981073\n",
      "317 Epoch: 0185 cost =  0.000047593 val =  0.981073\n",
      "317 Epoch: 0186 cost =  0.000046539 val =  0.981073\n",
      "317 Epoch: 0187 cost =  0.000046273 val =  0.981073\n",
      "317 Epoch: 0188 cost =  0.000044973 val =  0.981073\n",
      "317 Epoch: 0189 cost =  0.000044291 val =  0.981073\n",
      "317 Epoch: 0190 cost =  0.000043502 val =  0.981073\n",
      "317 Epoch: 0191 cost =  0.000042912 val =  0.981073\n",
      "317 Epoch: 0192 cost =  0.000041939 val =  0.981073\n",
      "317 Epoch: 0193 cost =  0.000041213 val =  0.981073\n",
      "317 Epoch: 0194 cost =  0.000040497 val =  0.981073\n",
      "317 Epoch: 0195 cost =  0.000040051 val =  0.981073\n",
      "317 Epoch: 0196 cost =  0.000039217 val =  0.981073\n",
      "317 Epoch: 0197 cost =  0.000038259 val =  0.981073\n",
      "317 Epoch: 0198 cost =  0.000037699 val =  0.981073\n",
      "317 Epoch: 0199 cost =  0.000037063 val =  0.981073\n",
      "317 Epoch: 0200 cost =  0.000036367 val =  0.981073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../model/CNN/cnn_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "batch_size = 32\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for epoch in range(training_epochs):#training epoch 500 / batch_size 128 --> acc 90%\n",
    "        avg_cost = 0\n",
    "        val_avg_cost =0\n",
    "        total_batch = int(y_train.shape[0] / batch_size)\n",
    "        for i in range(0, y_train.shape[0], batch_size):\n",
    "            feed_dict={X:X_train2[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "            cost_history = np.append(cost_history,cost)\n",
    "            avg_cost += c/total_batch \n",
    "\n",
    "        y_pred = sess.run(logits, feed_dict={X:X_val2})\n",
    "        y_pred = sess.run(tf.argmax(y_pred,1))\n",
    "        y_true = y_val\n",
    "\n",
    "        y_true = sess.run(tf.argmax(y_true,1))\n",
    "        print(len(y_pred),end=' ')\n",
    "        print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost), 'val = ','%f' %(accuracy_score(y_true, y_pred)) )\n",
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.992\n",
      "Accuracy:  0.9924242424242424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       290\n",
      "           1       0.98      0.99      0.99       106\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       396\n",
      "   macro avg       0.99      0.99      0.99       396\n",
      "weighted avg       0.99      0.99      0.99       396\n",
      "\n",
      "[[288   2]\n",
      " [  1 105]]\n"
     ]
    }
   ],
   "source": [
    "# Print Result\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

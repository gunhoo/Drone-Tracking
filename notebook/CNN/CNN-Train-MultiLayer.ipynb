{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have been save the data, you don't have to preprocessing and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_path = '../../data/drone/*.wav'\n",
    "background_path = '../../data/background/*.wav'\n",
    "\n",
    "drone_files = glob.glob(drone_path)\n",
    "background_files = glob.glob(background_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 44100\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983765,)\n",
      "(2799903,)\n"
     ]
    }
   ],
   "source": [
    "drone_raw = load(drone_files)\n",
    "background_raw = load(background_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=44100, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983765,)\n",
      "small end: (16, 12)\n",
      "small end: (16, 4)\n",
      "(2799903,)\n",
      "small end: (16, 13)\n",
      "small end: (16, 5)\n",
      "(727, 16, 16) (727,)\n",
      "(682, 16, 16) (682,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_drone, y_drone = mfcc4(drone_raw, 1)\n",
    "mfcc_background, y_background = mfcc4(background_raw, 0)\n",
    "\n",
    "print(mfcc_drone.shape, y_drone.shape)\n",
    "print(mfcc_background.shape, y_background.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 16, 16) (1409,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_drone, mfcc_background), axis=0)\n",
    "#X = np.concatenate((mfcc_drone), axis=0)\n",
    "#X = X.reshape(-1, 16,16,1)\n",
    "y = np.hstack((y_drone, y_background))\n",
    "#y = np.hstack(y_drone)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 2)\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(901, 16, 16) (282, 16, 16)\n",
      "(226, 16, 16) (226, 2)\n",
      "(901, 2) (282, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save('../../data/X_train', X_train)\n",
    "np.save('../../data/X_test', X_test)\n",
    "np.save('../../model/X_val', X_val)\n",
    "np.save('../../model/y_val', y_val)\n",
    "np.save('../../data/y_train', y_train)\n",
    "np.save('../../data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load('../../data/X_train.npy')\n",
    "X_test = np.load('../../data/X_test.npy')\n",
    "X_val = np.load('../../model/X_val.npy')\n",
    "y_val = np.load('../../model/y_val.npy')\n",
    "y_train = np.load('../../data/y_train.npy')\n",
    "y_test = np.load('../../data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - One convolutional layer /w no dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Experiment 3-2\n",
    "- learning rate 0.005\n",
    "- pooling stride 1x1\n",
    "- #filter 1\n",
    "- best result among every other settings\n",
    "- cost kept fluctuated during training. (0.8 -> 1.3) -- why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.0002  # 0.005\n",
    "training_epochs = 500 # 수정해봐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# dropout넣어야하나\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "# 여기도\n",
    "flat = tf.reshape(pool2, [-1, 16*16*1])\n",
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_val2 = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model_path = '../../model/CNN/cnn_model'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0001 cost =  3.786671849 val =  0.849558\n",
      "226 Epoch: 0002 cost =  0.565626863 val =  0.929204\n",
      "226 Epoch: 0003 cost =  0.480582451 val =  0.924779\n",
      "226 Epoch: 0004 cost =  0.255880576 val =  0.946903\n",
      "226 Epoch: 0005 cost =  0.177414688 val =  0.969027\n",
      "226 Epoch: 0006 cost =  0.189629713 val =  0.969027\n",
      "226 Epoch: 0007 cost =  0.121860784 val =  0.964602\n",
      "226 Epoch: 0008 cost =  0.106408667 val =  0.964602\n",
      "226 Epoch: 0009 cost =  0.040741752 val =  0.969027\n",
      "226 Epoch: 0010 cost =  0.047854323 val =  0.969027\n",
      "226 Epoch: 0011 cost =  0.037638588 val =  0.969027\n",
      "226 Epoch: 0012 cost =  0.042033660 val =  0.973451\n",
      "226 Epoch: 0013 cost =  0.035748356 val =  0.973451\n",
      "226 Epoch: 0014 cost =  0.036117215 val =  0.973451\n",
      "226 Epoch: 0015 cost =  0.033483518 val =  0.973451\n",
      "226 Epoch: 0016 cost =  0.031887281 val =  0.973451\n",
      "226 Epoch: 0017 cost =  0.030252928 val =  0.973451\n",
      "226 Epoch: 0018 cost =  0.028798112 val =  0.973451\n",
      "226 Epoch: 0019 cost =  0.027683277 val =  0.977876\n",
      "226 Epoch: 0020 cost =  0.026586773 val =  0.977876\n",
      "226 Epoch: 0021 cost =  0.025461511 val =  0.977876\n",
      "226 Epoch: 0022 cost =  0.024579206 val =  0.977876\n",
      "226 Epoch: 0023 cost =  0.023274893 val =  0.977876\n",
      "226 Epoch: 0024 cost =  0.022146975 val =  0.977876\n",
      "226 Epoch: 0025 cost =  0.022179670 val =  0.982301\n",
      "226 Epoch: 0026 cost =  0.029812584 val =  0.982301\n",
      "226 Epoch: 0027 cost =  0.080047419 val =  0.986726\n",
      "226 Epoch: 0028 cost =  0.031307953 val =  0.977876\n",
      "226 Epoch: 0029 cost =  0.027925676 val =  0.977876\n",
      "226 Epoch: 0030 cost =  0.024286248 val =  0.982301\n",
      "226 Epoch: 0031 cost =  0.025886652 val =  0.977876\n",
      "226 Epoch: 0032 cost =  0.027607350 val =  0.977876\n",
      "226 Epoch: 0033 cost =  0.028558711 val =  0.977876\n",
      "226 Epoch: 0034 cost =  0.028802238 val =  0.977876\n",
      "226 Epoch: 0035 cost =  0.028436213 val =  0.982301\n",
      "226 Epoch: 0036 cost =  0.227517780 val =  0.969027\n",
      "226 Epoch: 0037 cost =  0.515309503 val =  0.955752\n",
      "226 Epoch: 0038 cost =  0.036797855 val =  0.982301\n",
      "226 Epoch: 0039 cost =  0.018585881 val =  0.986726\n",
      "226 Epoch: 0040 cost =  0.014489945 val =  0.991150\n",
      "226 Epoch: 0041 cost =  0.010610163 val =  0.977876\n",
      "226 Epoch: 0042 cost =  0.010596841 val =  0.982301\n",
      "226 Epoch: 0043 cost =  0.048621581 val =  0.986726\n",
      "226 Epoch: 0044 cost =  0.112840681 val =  0.991150\n",
      "226 Epoch: 0045 cost =  0.224591710 val =  0.977876\n",
      "226 Epoch: 0046 cost =  0.461772721 val =  0.973451\n",
      "226 Epoch: 0047 cost =  0.291715416 val =  0.960177\n",
      "226 Epoch: 0048 cost =  0.116966649 val =  0.964602\n",
      "226 Epoch: 0049 cost =  0.202243104 val =  0.960177\n",
      "226 Epoch: 0050 cost =  0.179087860 val =  0.964602\n",
      "226 Epoch: 0051 cost =  0.094845863 val =  0.982301\n",
      "226 Epoch: 0052 cost =  0.018639418 val =  0.982301\n",
      "226 Epoch: 0053 cost =  0.005572287 val =  0.982301\n",
      "226 Epoch: 0054 cost =  0.021248001 val =  0.995575\n",
      "226 Epoch: 0055 cost =  0.005102616 val =  0.986726\n",
      "226 Epoch: 0056 cost =  0.011345073 val =  0.982301\n",
      "226 Epoch: 0057 cost =  0.005072253 val =  0.982301\n",
      "226 Epoch: 0058 cost =  0.018684127 val =  0.991150\n",
      "226 Epoch: 0059 cost =  0.003536643 val =  0.982301\n",
      "226 Epoch: 0060 cost =  0.014657340 val =  0.991150\n",
      "226 Epoch: 0061 cost =  0.003427903 val =  0.982301\n",
      "226 Epoch: 0062 cost =  0.014008157 val =  0.991150\n",
      "226 Epoch: 0063 cost =  0.003647749 val =  0.982301\n",
      "226 Epoch: 0064 cost =  0.013556757 val =  0.986726\n",
      "226 Epoch: 0065 cost =  0.004401856 val =  0.982301\n",
      "226 Epoch: 0066 cost =  0.013588608 val =  0.986726\n",
      "226 Epoch: 0067 cost =  0.005647221 val =  0.982301\n",
      "226 Epoch: 0068 cost =  0.010729889 val =  0.986726\n",
      "226 Epoch: 0069 cost =  0.005170100 val =  0.982301\n",
      "226 Epoch: 0070 cost =  0.010166361 val =  0.986726\n",
      "226 Epoch: 0071 cost =  0.004368333 val =  0.982301\n",
      "226 Epoch: 0072 cost =  0.009673769 val =  0.986726\n",
      "226 Epoch: 0073 cost =  0.004313485 val =  0.982301\n",
      "226 Epoch: 0074 cost =  0.009098506 val =  0.986726\n",
      "226 Epoch: 0075 cost =  0.003566467 val =  0.982301\n",
      "226 Epoch: 0076 cost =  0.008730607 val =  0.986726\n",
      "226 Epoch: 0077 cost =  0.004604515 val =  0.982301\n",
      "226 Epoch: 0078 cost =  0.007749738 val =  0.986726\n",
      "226 Epoch: 0079 cost =  0.003185933 val =  0.986726\n",
      "226 Epoch: 0080 cost =  0.007502605 val =  0.986726\n",
      "226 Epoch: 0081 cost =  0.007499386 val =  0.982301\n",
      "226 Epoch: 0082 cost =  0.006271320 val =  0.986726\n",
      "226 Epoch: 0083 cost =  0.006235507 val =  0.986726\n",
      "226 Epoch: 0084 cost =  0.006859876 val =  0.982301\n",
      "226 Epoch: 0085 cost =  0.005449262 val =  0.986726\n",
      "226 Epoch: 0086 cost =  0.006202417 val =  0.986726\n",
      "226 Epoch: 0087 cost =  0.005832947 val =  0.982301\n",
      "226 Epoch: 0088 cost =  0.005125708 val =  0.986726\n",
      "226 Epoch: 0089 cost =  0.005991959 val =  0.986726\n",
      "226 Epoch: 0090 cost =  0.003314074 val =  0.982301\n",
      "226 Epoch: 0091 cost =  0.010362825 val =  0.995575\n",
      "226 Epoch: 0092 cost =  0.001980593 val =  0.982301\n",
      "226 Epoch: 0093 cost =  0.010070114 val =  0.991150\n",
      "226 Epoch: 0094 cost =  0.003505950 val =  0.982301\n",
      "226 Epoch: 0095 cost =  0.007489304 val =  0.991150\n",
      "226 Epoch: 0096 cost =  0.003849358 val =  0.982301\n",
      "226 Epoch: 0097 cost =  0.005603934 val =  0.986726\n",
      "226 Epoch: 0098 cost =  0.002395125 val =  0.982301\n",
      "226 Epoch: 0099 cost =  0.007176549 val =  0.986726\n",
      "226 Epoch: 0100 cost =  0.003732409 val =  0.982301\n",
      "226 Epoch: 0101 cost =  0.005165447 val =  0.986726\n",
      "226 Epoch: 0102 cost =  0.001932800 val =  0.986726\n",
      "226 Epoch: 0103 cost =  0.005972967 val =  0.991150\n",
      "226 Epoch: 0104 cost =  0.004326736 val =  0.982301\n",
      "226 Epoch: 0105 cost =  0.003777345 val =  0.986726\n",
      "226 Epoch: 0106 cost =  0.002374476 val =  0.982301\n",
      "226 Epoch: 0107 cost =  0.044310346 val =  0.982301\n",
      "226 Epoch: 0108 cost =  0.018800190 val =  0.977876\n",
      "226 Epoch: 0109 cost =  0.104601547 val =  0.907080\n",
      "226 Epoch: 0110 cost =  1.093856260 val =  0.986726\n",
      "226 Epoch: 0111 cost =  0.076651643 val =  0.982301\n",
      "226 Epoch: 0112 cost =  0.071925031 val =  0.986726\n",
      "226 Epoch: 0113 cost =  0.005030764 val =  0.986726\n",
      "226 Epoch: 0114 cost =  0.009107493 val =  0.982301\n",
      "226 Epoch: 0115 cost =  0.022097528 val =  0.991150\n",
      "226 Epoch: 0116 cost =  0.001380483 val =  0.986726\n",
      "226 Epoch: 0117 cost =  0.006834558 val =  0.982301\n",
      "226 Epoch: 0118 cost =  0.034998539 val =  0.986726\n",
      "226 Epoch: 0119 cost =  0.006462150 val =  0.991150\n",
      "226 Epoch: 0120 cost =  0.002129051 val =  0.991150\n",
      "226 Epoch: 0121 cost =  0.001398004 val =  0.991150\n",
      "226 Epoch: 0122 cost =  0.000430162 val =  0.995575\n",
      "226 Epoch: 0123 cost =  0.000251192 val =  0.991150\n",
      "226 Epoch: 0124 cost =  0.000387681 val =  0.995575\n",
      "226 Epoch: 0125 cost =  0.000242858 val =  0.991150\n",
      "226 Epoch: 0126 cost =  0.000358941 val =  0.995575\n",
      "226 Epoch: 0127 cost =  0.000233173 val =  0.991150\n",
      "226 Epoch: 0128 cost =  0.000324259 val =  0.995575\n",
      "226 Epoch: 0129 cost =  0.000213385 val =  0.991150\n",
      "226 Epoch: 0130 cost =  0.000273132 val =  0.995575\n",
      "226 Epoch: 0131 cost =  0.000180061 val =  0.991150\n",
      "226 Epoch: 0132 cost =  0.000208593 val =  0.995575\n",
      "226 Epoch: 0133 cost =  0.000142815 val =  0.991150\n",
      "226 Epoch: 0134 cost =  0.000154487 val =  0.991150\n",
      "226 Epoch: 0135 cost =  0.000122599 val =  0.991150\n",
      "226 Epoch: 0136 cost =  0.000128814 val =  0.991150\n",
      "226 Epoch: 0137 cost =  0.000117034 val =  0.991150\n",
      "226 Epoch: 0138 cost =  0.000119069 val =  0.991150\n",
      "226 Epoch: 0139 cost =  0.000114193 val =  0.991150\n",
      "226 Epoch: 0140 cost =  0.000114124 val =  0.991150\n",
      "226 Epoch: 0141 cost =  0.000111650 val =  0.991150\n",
      "226 Epoch: 0142 cost =  0.000110750 val =  0.991150\n",
      "226 Epoch: 0143 cost =  0.000109020 val =  0.991150\n",
      "226 Epoch: 0144 cost =  0.000107873 val =  0.991150\n",
      "226 Epoch: 0145 cost =  0.000106460 val =  0.991150\n",
      "226 Epoch: 0146 cost =  0.000105285 val =  0.991150\n",
      "226 Epoch: 0147 cost =  0.000104035 val =  0.991150\n",
      "226 Epoch: 0148 cost =  0.000102893 val =  0.991150\n",
      "226 Epoch: 0149 cost =  0.000101747 val =  0.991150\n",
      "226 Epoch: 0150 cost =  0.000100665 val =  0.991150\n",
      "226 Epoch: 0151 cost =  0.000099616 val =  0.991150\n",
      "226 Epoch: 0152 cost =  0.000098561 val =  0.991150\n",
      "226 Epoch: 0153 cost =  0.000097575 val =  0.991150\n",
      "226 Epoch: 0154 cost =  0.000096597 val =  0.991150\n",
      "226 Epoch: 0155 cost =  0.000095648 val =  0.991150\n",
      "226 Epoch: 0156 cost =  0.000094721 val =  0.991150\n",
      "226 Epoch: 0157 cost =  0.000093823 val =  0.991150\n",
      "226 Epoch: 0158 cost =  0.000092948 val =  0.991150\n",
      "226 Epoch: 0159 cost =  0.000092089 val =  0.991150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0160 cost =  0.000091255 val =  0.991150\n",
      "226 Epoch: 0161 cost =  0.000090436 val =  0.991150\n",
      "226 Epoch: 0162 cost =  0.000089634 val =  0.991150\n",
      "226 Epoch: 0163 cost =  0.000088852 val =  0.991150\n",
      "226 Epoch: 0164 cost =  0.000088083 val =  0.991150\n",
      "226 Epoch: 0165 cost =  0.000087331 val =  0.991150\n",
      "226 Epoch: 0166 cost =  0.000086590 val =  0.991150\n",
      "226 Epoch: 0167 cost =  0.000085869 val =  0.991150\n",
      "226 Epoch: 0168 cost =  0.000085156 val =  0.991150\n",
      "226 Epoch: 0169 cost =  0.000084441 val =  0.991150\n",
      "226 Epoch: 0170 cost =  0.000083779 val =  0.991150\n",
      "226 Epoch: 0171 cost =  0.000083083 val =  0.991150\n",
      "226 Epoch: 0172 cost =  0.000082426 val =  0.991150\n",
      "226 Epoch: 0173 cost =  0.000081764 val =  0.991150\n",
      "226 Epoch: 0174 cost =  0.000081121 val =  0.991150\n",
      "226 Epoch: 0175 cost =  0.000080496 val =  0.991150\n",
      "226 Epoch: 0176 cost =  0.000079845 val =  0.991150\n",
      "226 Epoch: 0177 cost =  0.000079239 val =  0.991150\n",
      "226 Epoch: 0178 cost =  0.000078613 val =  0.991150\n",
      "226 Epoch: 0179 cost =  0.000078016 val =  0.991150\n",
      "226 Epoch: 0180 cost =  0.000077405 val =  0.991150\n",
      "226 Epoch: 0181 cost =  0.000076824 val =  0.991150\n",
      "226 Epoch: 0182 cost =  0.000076229 val =  0.991150\n",
      "226 Epoch: 0183 cost =  0.000075654 val =  0.991150\n",
      "226 Epoch: 0184 cost =  0.000075076 val =  0.991150\n",
      "226 Epoch: 0185 cost =  0.000074510 val =  0.991150\n",
      "226 Epoch: 0186 cost =  0.000073945 val =  0.991150\n",
      "226 Epoch: 0187 cost =  0.000073388 val =  0.991150\n",
      "226 Epoch: 0188 cost =  0.000072840 val =  0.991150\n",
      "226 Epoch: 0189 cost =  0.000072287 val =  0.991150\n",
      "226 Epoch: 0190 cost =  0.000071760 val =  0.991150\n",
      "226 Epoch: 0191 cost =  0.000071201 val =  0.991150\n",
      "226 Epoch: 0192 cost =  0.000070668 val =  0.991150\n",
      "226 Epoch: 0193 cost =  0.000070143 val =  0.991150\n",
      "226 Epoch: 0194 cost =  0.000069611 val =  0.991150\n",
      "226 Epoch: 0195 cost =  0.000069091 val =  0.991150\n",
      "226 Epoch: 0196 cost =  0.000068568 val =  0.991150\n",
      "226 Epoch: 0197 cost =  0.000068053 val =  0.991150\n",
      "226 Epoch: 0198 cost =  0.000067534 val =  0.991150\n",
      "226 Epoch: 0199 cost =  0.000067023 val =  0.991150\n",
      "226 Epoch: 0200 cost =  0.000066520 val =  0.991150\n",
      "226 Epoch: 0201 cost =  0.000066025 val =  0.991150\n",
      "226 Epoch: 0202 cost =  0.000065508 val =  0.991150\n",
      "226 Epoch: 0203 cost =  0.000065018 val =  0.991150\n",
      "226 Epoch: 0204 cost =  0.000064510 val =  0.991150\n",
      "226 Epoch: 0205 cost =  0.000064024 val =  0.991150\n",
      "226 Epoch: 0206 cost =  0.000063524 val =  0.991150\n",
      "226 Epoch: 0207 cost =  0.000063041 val =  0.991150\n",
      "226 Epoch: 0208 cost =  0.000062544 val =  0.991150\n",
      "226 Epoch: 0209 cost =  0.000062070 val =  0.991150\n",
      "226 Epoch: 0210 cost =  0.000061577 val =  0.991150\n",
      "226 Epoch: 0211 cost =  0.000061113 val =  0.991150\n",
      "226 Epoch: 0212 cost =  0.000060613 val =  0.991150\n",
      "226 Epoch: 0213 cost =  0.000060152 val =  0.991150\n",
      "226 Epoch: 0214 cost =  0.000059664 val =  0.991150\n",
      "226 Epoch: 0215 cost =  0.000059196 val =  0.991150\n",
      "226 Epoch: 0216 cost =  0.000058688 val =  0.991150\n",
      "226 Epoch: 0217 cost =  0.000058187 val =  0.991150\n",
      "226 Epoch: 0218 cost =  0.000057690 val =  0.991150\n",
      "226 Epoch: 0219 cost =  0.000057235 val =  0.991150\n",
      "226 Epoch: 0220 cost =  0.000056792 val =  0.991150\n",
      "226 Epoch: 0221 cost =  0.000056306 val =  0.991150\n",
      "226 Epoch: 0222 cost =  0.000055812 val =  0.991150\n",
      "226 Epoch: 0223 cost =  0.000055329 val =  0.991150\n",
      "226 Epoch: 0224 cost =  0.000054830 val =  0.991150\n",
      "226 Epoch: 0225 cost =  0.000054321 val =  0.991150\n",
      "226 Epoch: 0226 cost =  0.000053810 val =  0.991150\n",
      "226 Epoch: 0227 cost =  0.000053347 val =  0.991150\n",
      "226 Epoch: 0228 cost =  0.000052877 val =  0.991150\n",
      "226 Epoch: 0229 cost =  0.000052458 val =  0.991150\n",
      "226 Epoch: 0230 cost =  0.000052019 val =  0.991150\n",
      "226 Epoch: 0231 cost =  0.000051564 val =  0.991150\n",
      "226 Epoch: 0232 cost =  0.000051118 val =  0.991150\n",
      "226 Epoch: 0233 cost =  0.000050675 val =  0.991150\n",
      "226 Epoch: 0234 cost =  0.000050233 val =  0.991150\n",
      "226 Epoch: 0235 cost =  0.000049793 val =  0.991150\n",
      "226 Epoch: 0236 cost =  0.000049360 val =  0.991150\n",
      "226 Epoch: 0237 cost =  0.000048909 val =  0.991150\n",
      "226 Epoch: 0238 cost =  0.000048485 val =  0.991150\n",
      "226 Epoch: 0239 cost =  0.000048046 val =  0.991150\n",
      "226 Epoch: 0240 cost =  0.000047617 val =  0.991150\n",
      "226 Epoch: 0241 cost =  0.000047184 val =  0.991150\n",
      "226 Epoch: 0242 cost =  0.000046756 val =  0.991150\n",
      "226 Epoch: 0243 cost =  0.000046344 val =  0.991150\n",
      "226 Epoch: 0244 cost =  0.000045912 val =  0.991150\n",
      "226 Epoch: 0245 cost =  0.000045496 val =  0.991150\n",
      "226 Epoch: 0246 cost =  0.000045078 val =  0.991150\n",
      "226 Epoch: 0247 cost =  0.000044660 val =  0.991150\n",
      "226 Epoch: 0248 cost =  0.000044252 val =  0.991150\n",
      "226 Epoch: 0249 cost =  0.000043836 val =  0.991150\n",
      "226 Epoch: 0250 cost =  0.000043437 val =  0.991150\n",
      "226 Epoch: 0251 cost =  0.000043013 val =  0.991150\n",
      "226 Epoch: 0252 cost =  0.000042624 val =  0.991150\n",
      "226 Epoch: 0253 cost =  0.000042213 val =  0.991150\n",
      "226 Epoch: 0254 cost =  0.000041817 val =  0.991150\n",
      "226 Epoch: 0255 cost =  0.000041415 val =  0.991150\n",
      "226 Epoch: 0256 cost =  0.000041020 val =  0.991150\n",
      "226 Epoch: 0257 cost =  0.000040631 val =  0.991150\n",
      "226 Epoch: 0258 cost =  0.000040233 val =  0.991150\n",
      "226 Epoch: 0259 cost =  0.000039853 val =  0.991150\n",
      "226 Epoch: 0260 cost =  0.000039459 val =  0.991150\n",
      "226 Epoch: 0261 cost =  0.000039089 val =  0.991150\n",
      "226 Epoch: 0262 cost =  0.000038699 val =  0.991150\n",
      "226 Epoch: 0263 cost =  0.000038335 val =  0.991150\n",
      "226 Epoch: 0264 cost =  0.000037955 val =  0.991150\n",
      "226 Epoch: 0265 cost =  0.000037586 val =  0.991150\n",
      "226 Epoch: 0266 cost =  0.000037210 val =  0.991150\n",
      "226 Epoch: 0267 cost =  0.000036845 val =  0.991150\n",
      "226 Epoch: 0268 cost =  0.000036484 val =  0.991150\n",
      "226 Epoch: 0269 cost =  0.000036113 val =  0.991150\n",
      "226 Epoch: 0270 cost =  0.000035765 val =  0.991150\n",
      "226 Epoch: 0271 cost =  0.000035396 val =  0.991150\n",
      "226 Epoch: 0272 cost =  0.000035045 val =  0.991150\n",
      "226 Epoch: 0273 cost =  0.000034690 val =  0.991150\n",
      "226 Epoch: 0274 cost =  0.000034342 val =  0.991150\n",
      "226 Epoch: 0275 cost =  0.000033986 val =  0.991150\n",
      "226 Epoch: 0276 cost =  0.000033650 val =  0.991150\n",
      "226 Epoch: 0277 cost =  0.000033306 val =  0.991150\n",
      "226 Epoch: 0278 cost =  0.000032965 val =  0.991150\n",
      "226 Epoch: 0279 cost =  0.000032621 val =  0.991150\n",
      "226 Epoch: 0280 cost =  0.000032290 val =  0.991150\n",
      "226 Epoch: 0281 cost =  0.000031956 val =  0.991150\n",
      "226 Epoch: 0282 cost =  0.000031623 val =  0.991150\n",
      "226 Epoch: 0283 cost =  0.000031300 val =  0.991150\n",
      "226 Epoch: 0284 cost =  0.000030967 val =  0.991150\n",
      "226 Epoch: 0285 cost =  0.000030645 val =  0.991150\n",
      "226 Epoch: 0286 cost =  0.000030313 val =  0.991150\n",
      "226 Epoch: 0287 cost =  0.000030001 val =  0.991150\n",
      "226 Epoch: 0288 cost =  0.000029689 val =  0.991150\n",
      "226 Epoch: 0289 cost =  0.000029378 val =  0.991150\n",
      "226 Epoch: 0290 cost =  0.000029065 val =  0.991150\n",
      "226 Epoch: 0291 cost =  0.000028759 val =  0.991150\n",
      "226 Epoch: 0292 cost =  0.000028450 val =  0.991150\n",
      "226 Epoch: 0293 cost =  0.000028149 val =  0.991150\n",
      "226 Epoch: 0294 cost =  0.000027855 val =  0.991150\n",
      "226 Epoch: 0295 cost =  0.000027489 val =  0.991150\n",
      "226 Epoch: 0296 cost =  0.000027216 val =  0.991150\n",
      "226 Epoch: 0297 cost =  0.000026997 val =  0.991150\n",
      "226 Epoch: 0298 cost =  0.000026680 val =  0.991150\n",
      "226 Epoch: 0299 cost =  0.000026402 val =  0.991150\n",
      "226 Epoch: 0300 cost =  0.000026120 val =  0.991150\n",
      "226 Epoch: 0301 cost =  0.000025838 val =  0.991150\n",
      "226 Epoch: 0302 cost =  0.000025559 val =  0.991150\n",
      "226 Epoch: 0303 cost =  0.000025279 val =  0.991150\n",
      "226 Epoch: 0304 cost =  0.000025010 val =  0.991150\n",
      "226 Epoch: 0305 cost =  0.000024733 val =  0.991150\n",
      "226 Epoch: 0306 cost =  0.000024469 val =  0.991150\n",
      "226 Epoch: 0307 cost =  0.000024203 val =  0.991150\n",
      "226 Epoch: 0308 cost =  0.000023937 val =  0.991150\n",
      "226 Epoch: 0309 cost =  0.000023672 val =  0.991150\n",
      "226 Epoch: 0310 cost =  0.000023415 val =  0.991150\n",
      "226 Epoch: 0311 cost =  0.000023155 val =  0.991150\n",
      "226 Epoch: 0312 cost =  0.000022908 val =  0.991150\n",
      "226 Epoch: 0313 cost =  0.000022651 val =  0.991150\n",
      "226 Epoch: 0314 cost =  0.000022400 val =  0.991150\n",
      "226 Epoch: 0315 cost =  0.000022146 val =  0.991150\n",
      "226 Epoch: 0316 cost =  0.000021904 val =  0.991150\n",
      "226 Epoch: 0317 cost =  0.000021665 val =  0.991150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0318 cost =  0.000021428 val =  0.991150\n",
      "226 Epoch: 0319 cost =  0.000021185 val =  0.991150\n",
      "226 Epoch: 0320 cost =  0.000020952 val =  0.991150\n",
      "226 Epoch: 0321 cost =  0.000020718 val =  0.991150\n",
      "226 Epoch: 0322 cost =  0.000020486 val =  0.991150\n",
      "226 Epoch: 0323 cost =  0.000020259 val =  0.991150\n",
      "226 Epoch: 0324 cost =  0.000020036 val =  0.991150\n",
      "226 Epoch: 0325 cost =  0.000019812 val =  0.991150\n",
      "226 Epoch: 0326 cost =  0.000019586 val =  0.991150\n",
      "226 Epoch: 0327 cost =  0.000019371 val =  0.991150\n",
      "226 Epoch: 0328 cost =  0.000019149 val =  0.991150\n",
      "226 Epoch: 0329 cost =  0.000018941 val =  0.991150\n",
      "226 Epoch: 0330 cost =  0.000018724 val =  0.991150\n",
      "226 Epoch: 0331 cost =  0.000018516 val =  0.991150\n",
      "226 Epoch: 0332 cost =  0.000018310 val =  0.991150\n",
      "226 Epoch: 0333 cost =  0.000018106 val =  0.991150\n",
      "226 Epoch: 0334 cost =  0.000017899 val =  0.991150\n",
      "226 Epoch: 0335 cost =  0.000017632 val =  0.991150\n",
      "226 Epoch: 0336 cost =  0.000017435 val =  0.991150\n",
      "226 Epoch: 0337 cost =  0.000017302 val =  0.991150\n",
      "226 Epoch: 0338 cost =  0.000017108 val =  0.991150\n",
      "226 Epoch: 0339 cost =  0.000016911 val =  0.991150\n",
      "226 Epoch: 0340 cost =  0.000016721 val =  0.991150\n",
      "226 Epoch: 0341 cost =  0.000016532 val =  0.991150\n",
      "226 Epoch: 0342 cost =  0.000016343 val =  0.991150\n",
      "226 Epoch: 0343 cost =  0.000016155 val =  0.991150\n",
      "226 Epoch: 0344 cost =  0.000015974 val =  0.991150\n",
      "226 Epoch: 0345 cost =  0.000015791 val =  0.991150\n",
      "226 Epoch: 0346 cost =  0.000015612 val =  0.991150\n",
      "226 Epoch: 0347 cost =  0.000015433 val =  0.991150\n",
      "226 Epoch: 0348 cost =  0.000015259 val =  0.991150\n",
      "226 Epoch: 0349 cost =  0.000015083 val =  0.991150\n",
      "226 Epoch: 0350 cost =  0.000014914 val =  0.991150\n",
      "226 Epoch: 0351 cost =  0.000014744 val =  0.991150\n",
      "226 Epoch: 0352 cost =  0.000014577 val =  0.991150\n",
      "226 Epoch: 0353 cost =  0.000014410 val =  0.991150\n",
      "226 Epoch: 0354 cost =  0.000014244 val =  0.991150\n",
      "226 Epoch: 0355 cost =  0.000014080 val =  0.991150\n",
      "226 Epoch: 0356 cost =  0.000013920 val =  0.991150\n",
      "226 Epoch: 0357 cost =  0.000013761 val =  0.991150\n",
      "226 Epoch: 0358 cost =  0.000013602 val =  0.991150\n",
      "226 Epoch: 0359 cost =  0.000013448 val =  0.991150\n",
      "226 Epoch: 0360 cost =  0.000013289 val =  0.991150\n",
      "226 Epoch: 0361 cost =  0.000013142 val =  0.991150\n",
      "226 Epoch: 0362 cost =  0.000012992 val =  0.991150\n",
      "226 Epoch: 0363 cost =  0.000012839 val =  0.991150\n",
      "226 Epoch: 0364 cost =  0.000012700 val =  0.991150\n",
      "226 Epoch: 0365 cost =  0.000012563 val =  0.991150\n",
      "226 Epoch: 0366 cost =  0.000012358 val =  0.991150\n",
      "226 Epoch: 0367 cost =  0.000012215 val =  0.991150\n",
      "226 Epoch: 0368 cost =  0.000012108 val =  0.991150\n",
      "226 Epoch: 0369 cost =  0.000011977 val =  0.991150\n",
      "226 Epoch: 0370 cost =  0.000011839 val =  0.991150\n",
      "226 Epoch: 0371 cost =  0.000011704 val =  0.991150\n",
      "226 Epoch: 0372 cost =  0.000011571 val =  0.995575\n",
      "226 Epoch: 0373 cost =  0.000011438 val =  0.995575\n",
      "226 Epoch: 0374 cost =  0.000011302 val =  0.995575\n",
      "226 Epoch: 0375 cost =  0.000011173 val =  0.995575\n",
      "226 Epoch: 0376 cost =  0.000011041 val =  0.995575\n",
      "226 Epoch: 0377 cost =  0.000010916 val =  0.995575\n",
      "226 Epoch: 0378 cost =  0.000010786 val =  0.995575\n",
      "226 Epoch: 0379 cost =  0.000010663 val =  0.995575\n",
      "226 Epoch: 0380 cost =  0.000010545 val =  0.995575\n",
      "226 Epoch: 0381 cost =  0.000010434 val =  0.995575\n",
      "226 Epoch: 0382 cost =  0.000010261 val =  0.995575\n",
      "226 Epoch: 0383 cost =  0.000010139 val =  0.995575\n",
      "226 Epoch: 0384 cost =  0.000010043 val =  0.995575\n",
      "226 Epoch: 0385 cost =  0.000009931 val =  0.995575\n",
      "226 Epoch: 0386 cost =  0.000009820 val =  0.995575\n",
      "226 Epoch: 0387 cost =  0.000009703 val =  0.995575\n",
      "226 Epoch: 0388 cost =  0.000009593 val =  0.995575\n",
      "226 Epoch: 0389 cost =  0.000009478 val =  0.995575\n",
      "226 Epoch: 0390 cost =  0.000009370 val =  0.995575\n",
      "226 Epoch: 0391 cost =  0.000009271 val =  0.995575\n",
      "226 Epoch: 0392 cost =  0.000009167 val =  0.995575\n",
      "226 Epoch: 0393 cost =  0.000009025 val =  0.995575\n",
      "226 Epoch: 0394 cost =  0.000008912 val =  0.995575\n",
      "226 Epoch: 0395 cost =  0.000008820 val =  0.995575\n",
      "226 Epoch: 0396 cost =  0.000008717 val =  0.995575\n",
      "226 Epoch: 0397 cost =  0.000008616 val =  0.995575\n",
      "226 Epoch: 0398 cost =  0.000008513 val =  0.995575\n",
      "226 Epoch: 0399 cost =  0.000008414 val =  0.995575\n",
      "226 Epoch: 0400 cost =  0.000008324 val =  0.995575\n",
      "226 Epoch: 0401 cost =  0.000008177 val =  0.995575\n",
      "226 Epoch: 0402 cost =  0.000008093 val =  0.995575\n",
      "226 Epoch: 0403 cost =  0.000008009 val =  0.995575\n",
      "226 Epoch: 0404 cost =  0.000007918 val =  0.995575\n",
      "226 Epoch: 0405 cost =  0.000007826 val =  0.995575\n",
      "226 Epoch: 0406 cost =  0.000007734 val =  0.995575\n",
      "226 Epoch: 0407 cost =  0.000007642 val =  0.995575\n",
      "226 Epoch: 0408 cost =  0.000007561 val =  0.995575\n",
      "226 Epoch: 0409 cost =  0.000007430 val =  0.995575\n",
      "226 Epoch: 0410 cost =  0.000007351 val =  0.995575\n",
      "226 Epoch: 0411 cost =  0.000007271 val =  0.995575\n",
      "226 Epoch: 0412 cost =  0.000007185 val =  0.995575\n",
      "226 Epoch: 0413 cost =  0.000007100 val =  0.995575\n",
      "226 Epoch: 0414 cost =  0.000007026 val =  0.995575\n",
      "226 Epoch: 0415 cost =  0.000006895 val =  0.995575\n",
      "226 Epoch: 0416 cost =  0.000006828 val =  0.995575\n",
      "226 Epoch: 0417 cost =  0.000006753 val =  0.995575\n",
      "226 Epoch: 0418 cost =  0.000006672 val =  0.995575\n",
      "226 Epoch: 0419 cost =  0.000006593 val =  0.995575\n",
      "226 Epoch: 0420 cost =  0.000006526 val =  0.995575\n",
      "226 Epoch: 0421 cost =  0.000006411 val =  0.995575\n",
      "226 Epoch: 0422 cost =  0.000006345 val =  0.995575\n",
      "226 Epoch: 0423 cost =  0.000006273 val =  0.995575\n",
      "226 Epoch: 0424 cost =  0.000006196 val =  0.995575\n",
      "226 Epoch: 0425 cost =  0.000006131 val =  0.995575\n",
      "226 Epoch: 0426 cost =  0.000006022 val =  0.995575\n",
      "226 Epoch: 0427 cost =  0.000005961 val =  0.995575\n",
      "226 Epoch: 0428 cost =  0.000005893 val =  0.995575\n",
      "226 Epoch: 0429 cost =  0.000005830 val =  0.995575\n",
      "226 Epoch: 0430 cost =  0.000005715 val =  0.995575\n",
      "226 Epoch: 0431 cost =  0.000005663 val =  0.995575\n",
      "226 Epoch: 0432 cost =  0.000005600 val =  0.995575\n",
      "226 Epoch: 0433 cost =  0.000005529 val =  0.995575\n",
      "226 Epoch: 0434 cost =  0.000005473 val =  0.995575\n",
      "226 Epoch: 0435 cost =  0.000005382 val =  0.995575\n",
      "226 Epoch: 0436 cost =  0.000005325 val =  0.995575\n",
      "226 Epoch: 0437 cost =  0.000005272 val =  0.995575\n",
      "226 Epoch: 0438 cost =  0.000005165 val =  0.995575\n",
      "226 Epoch: 0439 cost =  0.000005120 val =  0.995575\n",
      "226 Epoch: 0440 cost =  0.000005059 val =  0.995575\n",
      "226 Epoch: 0441 cost =  0.000005008 val =  0.995575\n",
      "226 Epoch: 0442 cost =  0.000004911 val =  0.995575\n",
      "226 Epoch: 0443 cost =  0.000004866 val =  0.995575\n",
      "226 Epoch: 0444 cost =  0.000004818 val =  0.995575\n",
      "226 Epoch: 0445 cost =  0.000004719 val =  0.995575\n",
      "226 Epoch: 0446 cost =  0.000004680 val =  0.995575\n",
      "226 Epoch: 0447 cost =  0.000004634 val =  0.995575\n",
      "226 Epoch: 0448 cost =  0.000004535 val =  0.995575\n",
      "226 Epoch: 0449 cost =  0.000004500 val =  0.995575\n",
      "226 Epoch: 0450 cost =  0.000004457 val =  0.995575\n",
      "226 Epoch: 0451 cost =  0.000004362 val =  0.995575\n",
      "226 Epoch: 0452 cost =  0.000004326 val =  0.995575\n",
      "226 Epoch: 0453 cost =  0.000004285 val =  0.995575\n",
      "226 Epoch: 0454 cost =  0.000004193 val =  0.995575\n",
      "226 Epoch: 0455 cost =  0.000004160 val =  0.995575\n",
      "226 Epoch: 0456 cost =  0.000004117 val =  0.995575\n",
      "226 Epoch: 0457 cost =  0.000004034 val =  0.995575\n",
      "226 Epoch: 0458 cost =  0.000004010 val =  0.995575\n",
      "226 Epoch: 0459 cost =  0.000003958 val =  0.995575\n",
      "226 Epoch: 0460 cost =  0.000003908 val =  0.995575\n",
      "226 Epoch: 0461 cost =  0.000003866 val =  0.995575\n",
      "226 Epoch: 0462 cost =  0.000003777 val =  0.995575\n",
      "226 Epoch: 0463 cost =  0.000003758 val =  0.995575\n",
      "226 Epoch: 0464 cost =  0.000003706 val =  0.995575\n",
      "226 Epoch: 0465 cost =  0.000003620 val =  0.995575\n",
      "226 Epoch: 0466 cost =  0.000003623 val =  0.995575\n",
      "226 Epoch: 0467 cost =  0.000003570 val =  0.995575\n",
      "226 Epoch: 0468 cost =  0.000003513 val =  0.995575\n",
      "226 Epoch: 0469 cost =  0.000003461 val =  0.995575\n",
      "226 Epoch: 0470 cost =  0.000003417 val =  0.995575\n",
      "226 Epoch: 0471 cost =  0.000003346 val =  0.995575\n",
      "226 Epoch: 0472 cost =  0.000003327 val =  0.995575\n",
      "226 Epoch: 0473 cost =  0.000003251 val =  0.995575\n",
      "226 Epoch: 0474 cost =  0.000003238 val =  0.995575\n",
      "226 Epoch: 0475 cost =  0.000003157 val =  0.995575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Epoch: 0476 cost =  0.000003151 val =  0.995575\n",
      "226 Epoch: 0477 cost =  0.000003073 val =  0.995575\n",
      "226 Epoch: 0478 cost =  0.000003074 val =  0.995575\n",
      "226 Epoch: 0479 cost =  0.000003005 val =  0.995575\n",
      "226 Epoch: 0480 cost =  0.000002995 val =  0.995575\n",
      "226 Epoch: 0481 cost =  0.000002948 val =  0.995575\n",
      "226 Epoch: 0482 cost =  0.000002887 val =  0.995575\n",
      "226 Epoch: 0483 cost =  0.000002885 val =  0.995575\n",
      "226 Epoch: 0484 cost =  0.000002841 val =  0.995575\n",
      "226 Epoch: 0485 cost =  0.000002866 val =  0.995575\n",
      "226 Epoch: 0486 cost =  0.000002733 val =  0.995575\n",
      "226 Epoch: 0487 cost =  0.000002734 val =  0.995575\n",
      "226 Epoch: 0488 cost =  0.000002669 val =  0.995575\n",
      "226 Epoch: 0489 cost =  0.000002663 val =  0.995575\n",
      "226 Epoch: 0490 cost =  0.000002584 val =  0.995575\n",
      "226 Epoch: 0491 cost =  0.000002600 val =  0.995575\n",
      "226 Epoch: 0492 cost =  0.000002557 val =  0.995575\n",
      "226 Epoch: 0493 cost =  0.000002522 val =  0.995575\n",
      "226 Epoch: 0494 cost =  0.000002445 val =  0.995575\n",
      "226 Epoch: 0495 cost =  0.000002453 val =  0.995575\n",
      "226 Epoch: 0496 cost =  0.000002382 val =  0.995575\n",
      "226 Epoch: 0497 cost =  0.000002379 val =  0.995575\n",
      "226 Epoch: 0498 cost =  0.000002350 val =  0.995575\n",
      "226 Epoch: 0499 cost =  0.000002292 val =  0.995575\n",
      "226 Epoch: 0500 cost =  0.000002289 val =  0.995575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../model/CNN/cnn_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "batch_size = 32\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "\n",
    "for epoch in range(training_epochs):#training epoch 500 / batch_size 128 --> acc 90%\n",
    "    avg_cost = 0\n",
    "    val_avg_cost =0\n",
    "    total_batch = int(y_train.shape[0] / batch_size)\n",
    "    for i in range(0, y_train.shape[0], batch_size):\n",
    "        feed_dict={X:X_train2[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "        avg_cost += c/total_batch \n",
    "    \n",
    "    y_pred = sess.run(logits, feed_dict={X:X_val2})\n",
    "    y_pred = sess.run(tf.argmax(y_pred,1))\n",
    "    y_true = y_val\n",
    "        \n",
    "    y_true = sess.run(tf.argmax(y_true,1))\n",
    "    print(len(y_pred),end=' ')\n",
    "    print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost), 'val = ','%f' %(accuracy_score(y_true, y_pred)) )\n",
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.996\n",
      "Accuracy:  0.9964539007092199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       134\n",
      "           1       0.99      1.00      1.00       148\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       282\n",
      "   macro avg       1.00      1.00      1.00       282\n",
      "weighted avg       1.00      1.00      1.00       282\n",
      "\n",
      "[[133   1]\n",
      " [  0 148]]\n"
     ]
    }
   ],
   "source": [
    "# Print Result\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
